---
title: '<img src="Figures/LogoColorRegular.jpg" style="float: right;width: 80px; "/>Generic Agricultural Water Quality Management Area Water Quality Status and Trends Report'
subtitle: Oregon DEQ's Water Quality Status and Trends Report for the Oregon Department of Agriculture's Biennial Review of the Agricultural Area Rules and Plans
date: January 2019
output:
  word_document:
    fig_caption: yes
    reference_docx: //deqhq1/WQNPS/Agriculture/Status_and_Trend_Analysis/R_support_files/Report_Template.docx
    toc: yes
  html_document:
    mode: selfcontained
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
always_allow_html: yes
---

```{r setup-packages-functions, include=FALSE}

library(knitr)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning=FALSE, 
                      error = FALSE,
                      cache = FALSE,
                      include = TRUE,
                      fig.keep='all',
                      fig.path='Figures/'
                      )

library(RODBC)
library(RCurl)
library(XML)
library(dataRetrieval)
library(plyr)
library(sp)
library(rgdal)
library(raster)
library(rgeos)
library(DT)
library(wq)
library(chron)
library(reshape)
library(reshape2)
library(ggplot2)
library(ggthemes)
library(zoo)
library(spatialEco)
library(dplyr)
library(lubridate)
library(ggthemes)
library(captioner)
library(plyr)
library(tidyr)
library(leaflet)

source('functions/funDataQuery.R')
source("functions/funHelpers.R")
source("functions/funClean.R")
source("functions/funSeaKen.R")
source("functions/funPlots.R")
source('functions/TualatinR_Allocations.R')
source('functions/funConclusions.R')

tbls  <- captioner(prefix="Table")
figs <- captioner(prefix="\nFigure")
```

```{r inputs}

# agwqma, query_dates, and project_dir are different for every Report. Note 'agwqma' must be named exactly 
# how it is named in the agwqma shapefile ('agwqma_all_shp').

agwqma <- "Generic"
query_dates <- c("2000-01-01", "2018-12-31")
project_dir <-  "//deqhq1/WQNPS/Agriculture/Status_and_Trend_Analysis/Generic/Generic"

# Set to TRUE if knitting a word document
word_output <- TRUE

# Set to TRUE if you want individual parameter summary maps for each parameter
split_param_summary <- FALSE

# Everything below here should not change
support_files_dir <- "//deqhq1/WQNPS/Agriculture/Status_and_Trend_Analysis/R_support_files"
Rdata_dir <- paste0(project_dir,"/RData")
GIS_dir <- paste0(project_dir,"/GIS")

# Name of input map files
landuse_map_file <- paste0(gsub(" ", "_", agwqma), "_landuse_map.png")
station_map_file <- paste0(gsub(" ", "_", agwqma), "_station_map.png")

station_summary_map1_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map1.png")
station_summary_map2_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map2.png")

station_summary_map_DO_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_DO.png")
station_summary_map_pH_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_pH.png")
station_summary_map_temp_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_temp.png")
station_summary_map_ecoli_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_ecoli.png")
station_summary_map_entero_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_entero.png")
station_summary_map_tss_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_tss.png")
station_summary_map_tp_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_tp.png")

# Name of output files
df_all_raw_file <- paste0(gsub(" ", "_", agwqma), "_df_all_raw_",paste(query_dates, collapse = "."), ".Rdata")
df_all_clean_file <- paste0(gsub(" ", "_", agwqma), "_df_all_clean_",paste(query_dates, collapse = "."), ".Rdata")
duplicates_file <- paste0(gsub(" ", "_", agwqma), "_duplicates_",paste(query_dates, collapse = "."), ".Rdata")
landuse_file <- paste0(gsub(" ", "_", agwqma), "_landuse.Rdata")
stns_file <- paste0(gsub(" ", "_", agwqma), "_stns.Rdata")
status_file <- paste0(gsub(" ", "_", agwqma), "_status.Rdata")
trend_file <- paste0(gsub(" ", "_", agwqma), "_trend.Rdata")
stns_param_summary_file <- paste0(gsub(" ", "_", agwqma), "_station_param_summary.Rdata")

# Sets up checks for Executive Summary generation
Executive_Summary_check <- Reduce("&", file.exists(paste0(Rdata_dir,"/", landuse_file), paste0(Rdata_dir,"/", stns_param_summary_file)))

input <- list(action_button = c(0))
input$select <- agwqma
input$dates <- query_dates
input$parms <- c('Total Phosphorus',
                 'Total Suspended Solids',
                 'Total Suspended Solids',
                 'Bacteria',
                 'Temperature',
                 'pH',
                 'Dissolved Oxygen'
                 # ,
                 # 'Total Nitrogen'
                 )

# Check if the local GIS directory exists
if (!file.exists(paste0(project_dir,"/GIS"))) {
    dir.create(paste0(project_dir,"/GIS"))
}

# Check if the local RData directory exists
if (!file.exists(paste0(project_dir,"/RData"))) {
    dir.create(paste0(project_dir,"/RData"))
}

# Check if the local Figures directory exists
if (!file.exists(paste0(project_dir,"/Figures"))) {
    dir.create(paste0(project_dir,"/Figures"))
}

```

```{r lookup-imports}

# import github Lookups
BC_LU <- read.csv("Lookups/BC_LU.csv")
Conc_LU <- read.csv("Lookups/Conclusions_LU.csv", na.strings = c("", "NA"))
OAR_LU <- read.csv("Lookups/OAR_LU.csv")
Ben_use_LU <- read.csv("Lookups/stations.csv", na.strings = c("", "NA"))
wq_limited <- read.csv('Lookups/wq_limited_2012_df_temp_bact_ph_DO_TP_Sediment.csv')
HUClist <- read.csv('Lookups/PlanHUC_LU.csv')
stations_huc <- read.csv('Lookups/station_wbd_12132016.csv')
ph_crit <- read.csv('Lookups/PlanOWRDBasinpH_LU.csv')
lu_parms <- read.csv('Lookups/WQP_Table3040_Names.csv', stringsAsFactors = FALSE)

ph_crit <- merge(ph_crit, HUClist, by.x = 'plan_name', by.y = 'PlanName', all.x = TRUE)

# import GIS features
agwqma_all_shp <- readOGR(dsn = support_files_dir, layer = 'ODA_AgWQMA', integer64="warn.loss", verbose = FALSE)
agwqma_shp <- agwqma_all_shp[agwqma_all_shp$PlanName == agwqma,]
tribal_lands_shp <- readOGR(dsn = support_files_dir, layer = 'tl_2017_or_aiannh', integer64="warn.loss", verbose = FALSE)
wql_streams_shp <- readOGR(dsn = support_files_dir, layer = 'WQL_Streams_2012', integer64="warn.loss", verbose = FALSE)
wql_streams_shp <- spTransform(wql_streams_shp, CRS("+proj=longlat +datum=NAD83"))

# Import Bacteria nonfreshwater GIS feature
bacteria_nonfreshwater_shp <- readOGR(dsn = support_files_dir, layer = 'bacteria_nonfreshwater', integer64="warn.loss", verbose = FALSE)

#hucs_shp <- readOGR(dsn = support_files_dir, layer = 'WBD_HU8', integer64="warn.loss", verbose = FALSE)

# Import other data frames
load(paste0(support_files_dir,'/NLCD2011_OR.Rdata'))
load(paste0(support_files_dir,'/OR_cats.Rdata'))

```

```{r AWQMS-Query, include=FALSE}

if(file.exists(file=paste0(Rdata_dir,"/",df_all_raw_file))) {
  
  print("loading existing raw df.all")
  load(file=paste0(Rdata_dir,"/",df_all_raw_file))
  
} else {
  
  AWQMS_Data <- AWQMS_Query(planArea = agwqma,
                            area.Shp = agwqma_shp,
                            inParms = input$parms,
                            luParms = lu_parms,
                            startDate = min(input$dates),
                            endDate = max(input$dates),
                            stations.Channel.Name = "STATIONS")
  
  df.all <- tryCatch(combine(A=AWQMS_Data),
                     error = function(err) 
                     {err <- geterrmessage()})
  
  save(df.all, file=paste0(Rdata_dir,"/",df_all_raw_file))
}

```

```{r Clean-df.all, include=FALSE}

if(file.exists(file=paste0(Rdata_dir,"/",df_all_clean_file))) {
  
  print("loading existing cleaned df.all")
  load(file=paste0(Rdata_dir,"/",df_all_clean_file))

} else {
  
  print("cleaning df.all")
  
  # remove data collected on tribal nation land or tribal trust land
  df.all <-df.all[df.all$Station_ID %in% Stations_in_poly(df.all, tribal_lands_shp, outside=TRUE),]
  
  
  # remove stations outside the agwqma
  df.all <- clipToPlanArea(df.all, agwqma_all_shp, input$select)

  # Convert AWQMS analyte names to existing code language
  df.all[grep('Dissolved oxygen', df.all$Analyte),]$Analyte <- 'Dissolved Oxygen'
  df.all[grep('Phosphorus', df.all$Analyte),]$Analyte <- 'Total Phosphorus'
  df.all[grep('Total suspended solids', df.all$Analyte),]$Analyte <- 'Total Suspended Solids'
  
  # Remove all Dissolved Oxygen summary statistics from analysis except for 'minimum' 
  df.all <- df.all %>% filter(!(Analyte == "Dissolved Oxygen" & Statistical_Base %in% c('7DADM', 'Maximum', 'Mean', '7DADMean', '7DADMin', '30DADMean')))
  
  # Reconcile the same ODEQ stations that have different IDs in WQP and DEQ Databases
  # The Station ID will be named the same as LASAR
  df.all$Station_ID <- gsub("OREGONDEQ-", "", df.all$Station_ID)
  df.all$Station_ID <- gsub("-ORDEQ", "", df.all$Station_ID)
  df.all$Station_ID <- gsub("21ORBCH-", "", df.all$Station_ID)
  
  # Reconcile Stations with the same ID but have different Lat/Longs 
  df.all <- remove_stn_dups(df.all)
  
  # Reconcile Stations with the same ID but have different Station Names.
  # This works but the issue should be investigatged further to determine if
  # the problem is coming from combining DEQ and WQP data.
  df <- df.all %>%
    dplyr::select(Station_ID, Station_Description) %>%
    dplyr::distinct(Station_ID, Station_Description)
  
  df <- df[!duplicated(df[c("Station_ID")] ), ]
  
  df.all <- merge(df, df.all, by= 'Station_ID') # keep .x
  
  colnames(df.all)[2] <- 'Station_Description'
  df.all$Station_Description.y <- NULL
  
  # Remove obervations that are the same
  # Same is defined as having the same station ID, Sample Date/time, Analyte, and Statistical_Base
  # Note the field 'Statistical_Base' is a code that identifies if the result 
  # is a calculated value like Daily Max or 7DADM.
  df.all <- remove.dups(df.all)
  
  df.all$Result <- clean(df.all$Result)
  df.all$Result <- suppressWarnings(as.numeric(df.all$Result))
  df.all <- MRLhandling(df.all)
  
  if ("Fecal Coliform" %in% df.all$Analyte) {
    fc2ec.stations <-Stations_in_poly(df.all[df.all$Analyte == "Fecal Coliform", ], bacteria_nonfreshwater_shp, outside=TRUE)
    df.all <- update_fc2ec(df.all, fc2ec.stations)
  }
  
  # Remove Enterococcus data from df.all where the Coastal Contact Recreation criterion doesn't apply
  
  # Create a subset of data only including "Enterococcus"
  df.temp.ent <- df.all[df.all$Analyte == 'Enterococcus',]
  
  # Create a vector of stations where the Enterococcus criterion apply
  df.temp.ent2 <- (Ben_use_LU[!is.na(Ben_use_LU$bacteria_use),]) 
  df.temp.ent2 <- unique(df.temp.ent2[(df.temp.ent2$AgArea == agwqma &  grepl("Coastal Contact Recreation",
                                                                              df.temp.ent2$bacteria_use)), c("Station_ID")])
  
  if(!identical(df.temp.ent2, character(0))) {
    
    # Create vector of stations inside bacteria_nonfreshwater polygon
    df.temp.ent3 <- unique(c(Stations_in_poly(df.temp.ent, bacteria_nonfreshwater_shp, outside=FALSE), df.temp.ent2))
  
    # Use logic to remove the stations 
    df.all <- df.all[!(!(df.all$Station_ID %in% df.temp.ent3) & df.all$Analyte == 'Enterococcus'),]
  }
  
  df.all <- remove_QAfail(df.all)
  
  # Run temperature sufficiency tests
  if (any('Temperature' %in% df.all$Analyte)) {
    df.all <- df.all %>% filter(!(Analyte == "Temperature" & Statistical_Base %in% c('7DADM', 'Minimum', 'Mean', '7DADMean', '7DADMin', '30DADMean')))
    tempStns <- temp_sufficiency_analysis(df.all)
    
    qc.1.pass <- filter(attributes(tempStns)$day_test, result == "pass")
    qc.2.pass <- filter(attributes(tempStns)$month_test, result == "pass")
    qc.3.pass <- filter(attributes(tempStns)$year_test, result == "pass")
    qc.1.stn <- filter(attributes(tempStns)$day_test, result == "pass")$Station_ID
    qc.2.stn <- filter(attributes(tempStns)$month_test, result == "pass")$Station_ID
    qc.3.stn <- filter(attributes(tempStns)$year_test, result == "pass")$Station_ID
    
    qc.1.pass$IDD <- paste0(qc.1.pass$Station_ID," ",qc.1.pass$date)
    
    df.all.temp <- df.all %>% 
      filter(Analyte == "Temperature")  %>%
      mutate(date = date(Sampled)) %>%
      mutate(IDD = paste0(Station_ID," ",date)) %>%
      merge(qc.1.pass[,c("result", "IDD")], by=c("IDD"), all=FALSE)

    
    df.all.temp$Result <- convert_temp_F_C(df.all.temp, result_column_name="Result", unit_column_name="Unit")
    df.all.temp$Unit <- "Celsius"
    
    df.sdadm <- Calculate.sdadm(df.all.temp, "Result", "Station_ID", "Sampled", '%Y-%m-%d %H:%M:%S')
    
    # Remove NAs
    df.sdadm <- df.sdadm[!(is.na(df.sdadm$sdadm)),]
    
    df.sdadm$IDD <- paste0(df.sdadm$Station_ID," ",df.sdadm$date)
    
    # Attempt at pulling the other df fields for each daily sample so it can be added back to sdadm
    df.all.temp.fields <- df.all.temp[!duplicated(df.all.temp[c("IDD")] ), ]
    
    # add it back
    df.sdadm <- merge(x=df.sdadm[,c("IDD", "sdadm")],y=df.all.temp.fields, by="IDD", all.x=TRUE)
    
    # Remove NAs from merge
    df.sdadm <- df.sdadm[!(is.na(df.sdadm$Station_ID)),]
    
    df.sdadm$Result <- df.sdadm$sdadm
    
    # only keep columns in df.all
    df.sdadm <- df.sdadm[,colnames(df.sdadm) %in% colnames(df.all)]
    
    df.sdadm$Analyte <- "Temperature"

    # now remove temperature from df.all and replace with 7DADM values
    df.all <- df.all %>%
      filter(!Analyte == "Temperature") %>%
      rbind(df.sdadm)
    
    if(NROW(qc.3.pass) > 0) {
      qc.3.pass$Analyte <- "Temperature"
      df.all$month <- month(df.all$Sampled)
      qc.3.pass <- dplyr::rename(qc.3.pass, monTest = result)
      df.all <- merge(df.all, qc.3.pass[,c("Station_ID", "month", "monTest", "Analyte")], 
                      by=c("Station_ID", "Analyte", "month"), all.x = TRUE, all.y = FALSE)
    } else {
       df.all$monTest <- "NA"
    }     
      
  }

  save(df.all, file=paste0(Rdata_dir,"/",df_all_clean_file))
  # save(df.all, file=paste0(Rdata_dir,"/", gsub(" ", "_", agwqma), "_df_all_clean_",paste(query_dates, collapse = "."), "_old.Rdata"))
  
}

```

```{r Create-other-dataframes}

if (any(c('pH', 'E. Coli', "Enterococcus", "Dissolved Oxygen", 'Total Phosphorus') %in% df.all$Analyte)) {
  seaken_other <- run_seaKen(filter(df.all, Analyte %in% c('pH', 
                                                           'E. Coli', 
                                                           "Enterococcus", 
                                                           "Dissolved Oxygen", 
                                                           'Total Phosphorus')))
} else {seaken_other <- data.frame()}

if(NROW(dplyr::filter(df.all, Analyte == "Temperature" & monTest == "pass")) > 0) {
  seaken_temp <- run_seaKen(dplyr::filter(df.all, Analyte == "Temperature" & monTest == "pass"))
} else {seaken_temp <- data.frame()}


if(NROW(dplyr::filter(df.all, Analyte == "Total Suspended Solids")) > 0) {
  
  if (input$select %in% c('Owyhee','Malheur River','Burnt River','Powder-Brownlee','Hells Canyon','Lower Snake Asotin')) {
    # Snake River - Hells Canyon TMDL
    
    seaken_tss <- df.all %>%
      filter(Analyte == "Total Suspended Solids") %>%
      filter(month(Sampled) %in% (5:9)) %>%
      mutate(Sampled=floor_date(Sampled, "month")) %>%
      group_by(Station_ID, Station_Description, DECIMAL_LAT, DECIMAL_LONG, Analyte, Sampled) %>%
      summarize(Result=mean(Result)) %>%
      run_seaKen()
    
  } else {
    # Other Area
    seaken_tss <- run_seaKen(filter(df.all, Analyte %in% c('Total Suspended Solids')))
  } 
} else {
  seaken_tss <- data.frame()
}

SeaKen <- rbind(seaken_other, seaken_temp, seaken_tss)

status_years <- seq(year(floor_date(ymd(input$dates[2]) - years(2), unit="year")), 
                    year(ymd(input$dates[2])), by = 1)

status <- Stations_Status(df.all, status.years=status_years)
trend <- Stations_Trend(df.all, SeaKen=SeaKen)

stns_by_year <- Stations_by_Year(df.all)

# sort by analyte and station ID
status <- status %>% arrange(Analyte, Station_ID)
trend <- trend %>% arrange(Analyte, Station_ID)

stns <- All_stns_fit_Criteria(trend = trend, 
                             status = status,
                             df.all = df.all)

#print(stns)

df.stns <- df.all[df.all$Station_ID %in% unique(stns$Station_ID),]
stn_totals <- summarizeByStation(df.stns)
all.sp <- generateStnLyrToPlot(df.stns, stn_totals) #changed lat and long names

writeOGR(obj=all.sp, dsn=GIS_dir, layer="stations_to_map", driver="ESRI Shapefile", overwrite_layer=TRUE)

all_stn_sp <- all_stn_sp(df.all)
stn_nlcd_df <- landUseAnalysis(all.sp, cats, NLCD2011)

save(stns, file = paste0(Rdata_dir,"/", stns_file))
save(status, file = paste0(Rdata_dir,"/", status_file))
save(trend, file = paste0(Rdata_dir,"/", trend_file))

```


```{r exec-summary, child='Exec_Summary_Child.Rmd', eval = Executive_Summary_check & word_output}

```

# Introduction

## Purpose

The Oregon Department of Agriculture (ODA) has adopted area rules (OAR `r OAR_LU[OAR_LU$AgArea %in% input$select,'OAR']`) and plans for the `r input$select` agricultural water quality management area. Oregon statute and administrative rules require ODA to consult with the Oregon Department of Environmental Quality (DEQ) during the biennial review of Agricultural Water Quality Management Area Rules and Plans [ORS 568.930][1.1].  DEQ Total Maximum Daily Load (TMDLs) and Nonpoint Source (NPS) program staff conduct these reviews based on ODA's biennial review schedule of their area rules and plans. ODA's Agriculture Water Quality Program is outcome based, explicitly describing prohibited conditions, similar to DEQ's TMDL and NPS programs which explicitly define water quality targets and goals.  The analysis of landscape conditions and water quality data is used for implementing these programs as well as identifying data gaps. 

This report presents data and analysis that will help DEQ fulfill its roles in the biennial review process described in the [Memorandum of Agreement](https://www.oregon.gov/ODA/shared/Documents/Publications/NaturalResources/DEQODAmoa.pdf) between ODA and DEQ. Water quality status and trends reports are created to inform discussions between DEQ Basin Coordinators and ODA Agriculture Water Quality Specialists prior to the Local Advisory Committee meeting. The discussions between DEQ and ODA prior to the LAC meeting could include: water quality and what's working and not working, source(s) and solutions, data needs and future monitoring to answer these questions. This report presents an analysis of water quality data readily accessible from public databases and available in sufficient quantity to indicate status and trends. Dependent on data availability, DEQ will use the available water quality data to answer the first three questions below. For the fourth bullet, the report is expected to inform DEQ Basin Coordinator analysis, interpretation, and discussion with ODA and the LAC about possible or potential sources of pollution:

*	What is the status of water quality? 
*	What is the trend in water quality? 
*	When applicable, are TMDL load allocations for total phosphorus and total suspended solids being met?
* Can water quality status and trends be attributed to a pollution source or sources?

DEQ basin coordinators review pertinent information including this report as part of ODA's biennial review. DEQ basin coordinators recommend changes and additional data and resources necessary to achieve water quality criterion and meet TMDL load allocations through ODA's survey. 

[1.1]: https://www.oregonlegislature.gov/bills_laws/ors/ors568.html

## Basin Contact


```{r basin-contact, results="asis"}

deq<- paste(BC_LU[BC_LU$AgArea %in% input$select, 'DEQ_bc_name'], BC_LU[BC_LU$AgArea %in% input$select, 'DEQ_bc_email'], sep = '; ')

oda<- paste(BC_LU[BC_LU$AgArea %in% input$select, 'ODA_agwqcoord_name'], BC_LU[BC_LU$AgArea %in% input$select, 'ODA_agwqcoord_number'], sep = '; ')

BC_table<-data.frame(input$select, deq, oda)
colnames(BC_table) <- c('Agricultural Water Quality Management Area', 'DEQ Basin Coordinator', 'ODA Agricultural Water Quality Specialist')

knitr::kable(BC_table,
             padding = 2, digits = 1, row.names = FALSE, caption = 
               tbls(name = "basinContact", caption =
                      "Oregon DEQ and ODA basin contacts.")
)

```


# Methods

## Data Sources

Water quality data were retrieved from DEQ's [AWQMS Database][2.1.1] which may include data submitted to DEQ from many other organizations (see Appendix for a complete list). Data were also retrieved from the U.S. Environmental Protection Agency ([WQX/Storet][2.1.2]) and U.S. Geological Survey [NWIS][2.1.3] (USGS 2016) databases via the [Water Quality Portal][2.1.4]). Data collected between `r format(ymd(input$dates[1]), format="%B %d, %Y")` and `r format(ymd(input$dates[2]), format="%B %d, %Y")` within the `r input$select` agricultural water quality management area were included in this report. Parameters included in the query were temperature, pH, dissolved oxygen, total suspended solids, total phosphorus, and bacteria (*E. coli*, fecal coliform, and *Enterococcus*). ** REMOVE IF NOT NEEDED. Stations located within the Confederated Tribes of Umatilla Indian Reservation were not included in this report. The Confederated Tribes of Umatilla administer Clean Water Act programs on the reservation.**

The data returned were evaluated for quality. Data that was rated under the [DEQ's Laboratory Quality Manual][2.1.5] (ODEQ 2013) guidelines were rated `r unique(df.all[!is.na(df.all$Status), 'Status'])`. EPA and USGS data were included unless result comments indicated problems with the data.

[2.1.1]: http://www.oregon.gov/deq/wq/Pages/WQdata.aspx
[2.1.2]: https://www.epa.gov/waterdata/water-quality-data-wqx
[2.1.3]: https://qwwebservices.usgs.gov/
[2.1.4]: https://www.waterqualitydata.us/
[2.1.5]: http://www.oregon.gov/deq/FilterDocs/DEQ91LAB0006QMP.pdf

## Analysis

The status of water quality standards attainment for dissolved oxygen, *E. coli*, *Enterococcus*, pH, and temperature samples were made in relation to the applicable numeric water quality criterion. For some waterbodies the applicable water quality criterion for these parameters is a narrative non-numeric criterion. In this situation, status was not determined. Status was also not determined for total suspended solids and total phosphorus samples because there is no applicable water quality criteria or TMDL allocations for these parameters. A status assessment was made at a monitoring station if data were available within the last whole two years in the period from `r format(floor_date(ymd(input$dates[2]) - years(2), unit="year"), format="%B %d, %Y")` to `r format(ymd(input$dates[2]), format="%B %d, %Y")`. 

Trends were calculated for dissolved oxygen, bacteria, pH, temperature, total phosphorus, and total suspended solids using a Seasonal Kendall test (Hirsch et al. 1982, Hirsch and Slack 1984, and Helsel and Hirsch 2002). A Seasonal Kendall test removes the influence of seasonal fluctuations by calculating a Mann Kendall test (Mann 1945) on each season separately and then comparing the slopes. A significant positive, negative, or steady trend was determined across all seasons and years when the significance of the seasonal slopes had a two-tailed p <= 0.20. A steady trend had a slope equal to zero.   Prior to applying the Seasonal Kendall test data were grouped into monthly "seasons." Multiple observations within any given month were collapsed into a single value using the median. A trend assessment was made at a monitoring station if data were available in a minimum of eight different years for any year in the period from `r format(ymd(input$dates[1]), format="%B %d, %Y")` to `r format(ymd(input$dates[2]), format="%B %d, %Y")`. The observations must have beeen made with an underlying regularity (e.g. samples were taken in the same months for at least eight years).

Stations that met the status or trend data requirements were assessed with the results presented in this report. In some cases a station had sufficient data for trend but not status because data were not available anytime in the last two years. In these cases the status was shown on the plot for the older data along with the trend result but the status was not recorded in the maps, summary tables, or conclusions.

Results for pH from both grab and continuous sample data were compared to the applicable water quality criterion as found in [OAR 340-041-0021][2.2.1].

Results for bacteria samples were compared to the applicable bacteria criterion as found in [OAR 340-041-0009][2.2.2]. The bacteria standard for freshwater contact recreation is based on the presence of *E. coli* compared to a single sample maximum and a geometric mean of five or more samples in a 90 day period. The bacteria standard for coastal water contact recreation is based on the presence of *Enterococcus* compared to a single sample maximum and a geometric mean of five or more samples in a 90 day period.

Dissolved oxygen status was assessed by comparing the observed concentration values to the applicable daily minimum water quality criterion found in [OAR 340-041-0016][2.2.3]. If the dissolved oxygen concentration exceeded the water quality criterion, but met the criteria for percent saturation at the same time, it was considered to be in compliance with the water quality criterion. These points were noted in the plots using a different shape. Assessments were not made against the seven and 30-day mean minimum dissolved oxygen criteria due to the general lack of continuous dissolved oxygen data.

Results for continuous temperature data were compared against the applicable temperature criteria found in [OAR 340-041-0028][2.2.4]. The applicable temperature criteria is based on the seven day average daily maximum (7DADM) stream temperature metric. In order to ensure there was sufficient continuous data to calculate 7DADM, at least one observation per hour from noon to midnight must have been recorded. In addition, each month can have no more than one day of missing observations to ensure that no more than 10% of the 7DADM results in that month were missing.

A land use summary was developed for all monitoring stations that fit the criteria to assess water quality status and/or trends. The summary was derived from the Stream-Catchment ([StreamCat](https://www.epa.gov/national-aquatic-resource-surveys/streamcat)) dataset developed by EPA for the National Rivers and Streams Assessment (USEPA 2016). StreamCat utilized the NHDPlus version 2.1 stream network (McKay et al 2012) and the 2011 National Landcover Database (NLCD) (Homer et al. 2015) to calculate the proportion of each NLCD landuse class within the watershed area contributing to each NHDPlus stream segment including the upstream watershed area. This means that the landuse summary for a particular station represents the landuse for the entire NHDPlus segment where the station is located including the watershed portion of the segment downstream of the station as well as watershed areas upstream of that segment. The streamCat derived NLCD proportions were summarized by DEQ into five unique classes: **Developed**, **Forest**, **Agriculture**, **Shrub and Grass**, and **Other**). Developed includes all the various NLCD classes for urban and developed areas (21-24). Forest includes the various forest and woody wetland classes (41, 42, 43, and 90). Agriculture includes Pasture/Hay (81) and Cultivated Crops (82). Shrub and Grass includes NLCD classes Shrub/Scrub (52), Grassland/Herbaceous (71), and Herbaceous Wetlands (95). Other includes open water (11), Perennial Ice/Snow (12), and Barren Land (31). A map was made showing station locations in relation to these landuse classifications or to the original 2011 national land cover dataset if viewing the html version of this report.

[2.2.1]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68713
[2.2.2]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68695
[2.2.3]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=68706
[2.2.4]: https://secure.sos.state.or.us/oard/viewSingleRule.action;JSESSIONID_OARD=Q--AbU9sI2gNpiU9aa_3IO93qbFAoGOHlZ2WHGSe8IsE0OGtWMuS!568786841?ruleVrsnRsn=244176

# Results

Within the `r input$select` Agricultural Water Quality Management Area, data from `r length(unique(stns$Station_ID))` monitoring stations were sufficient to assess status and/or trends out of `r length(unique(df.all$Station_ID))` total monitoring stations. 

```{r results-summary, results='asis'}

station_summary_tbl <- data.frame(Analyte=c("_E. coli_","_Enterococcus_","Dissolved Oxygen","pH","Temperature","Total Phosphorus","TSS"),
                                  status=c(nrow(unique(status[status$Analyte == "E. Coli", ])),
                                           nrow(unique(status[status$Analyte == "Enterococcus", ])),
                                           nrow(unique(status[status$Analyte == "Dissolved Oxygen", ])),
                                           nrow(unique(status[status$Analyte == "pH", ])),
                                           nrow(unique(status[status$Analyte == "Temperature", ])),
                                           nrow(unique(status[status$Analyte == "Total Phosphorus", ])),
                                           nrow(unique(status[status$Analyte == "Total Suspended Solids", ]))
                                           ),
                                  trends=c(nrow(unique(trend[trend$Analyte == "E. Coli", ])),
                                           nrow(unique(trend[trend$Analyte == "Enterococcus", ])),
                                           nrow(unique(trend[trend$Analyte == "Dissolved Oxygen", ])),
                                           nrow(unique(trend[trend$Analyte == "pH",])),
                                           nrow(unique(trend[trend$Analyte == "Temperature", ])),
                                           nrow(unique(trend[trend$Analyte == "Total Phosphorus", ])),
                                           nrow(unique(trend[trend$Analyte == "Total Suspended Solids", ]))
                                           ))
colnames(station_summary_tbl) <- c("Analyte", "Number of stations w/ sufficient data for status analysis", "Number of stations w/ sufficient data for trend analysis")                                  

knitr::kable(station_summary_tbl, digits = 0, padding = 2, row.names = FALSE, caption = tbls(name = "StnSumTable", caption = "Summary of stations with sufficient data for status or trend analysis."))                                 

```

## Station Locations

The map in `r figs("stationsmap", display="cite")` shows the general location of monitoring stations that fit the status and/or trend data requirements along with the distribution of federal and non-federal lands. 


```{r stations-map-word, eval = word_output, results = "asis", fig.cap=figs(name="stationsmap", caption=paste0("Monitoring station locations within the ", agwqma, " Agricultural Water Quality Management Area."))}

knitr::include_graphics(path = paste0("Figures/", station_map_file))

```

## Land Use

The map in `r figs("landusemap", display="cite")` shows station location in relation to the 2011 national land cover dataset (Homer et al. 2015).

```{r landuse-map-word, eval = word_output, results = "asis", fig.cap=figs(name="landusemap", caption=paste0("Land use and land cover within the ", agwqma, " Agricultural Water Quality Management Area."))}

knitr::include_graphics(path = paste0("Figures/", landuse_map_file))

```


```{r landuse-map-html, results= 'asis', eval = !(word_output), fig.width=8.5, fig.height=7, fig.cap=figs(name="landusemap", caption=paste0("Land use and land cover within the ", agwqma, " Agricultural Water Quality Management Area."))}

agwqma_shp <-spTransform(agwqma_shp, CRS("+proj=longlat +datum=NAD83"))

map <- leaflet(agwqma_shp) %>%
  addPolygons(fill=FALSE, group = "AgWQMA") %>%
  addTiles() %>%
  addMarkers(data = all.sp, 
             lng = all.sp@coords[,1], 
             lat = all.sp@coords[,2], 
             popup = paste("<style> div.leaflet-popup-content {width:auto !important;}</style>",
                           lapply(rownames(all.sp@data), 
                                  function(row) {
                                    htmlTable::htmlTable(all.sp@data[row,],
                                                         header = c("Station ID", "Station Description",
                                                                    names(all.sp@data)[-c(1,2)]),
                                                         rnames = FALSE)
                                  })),
             group = 'Stations That Fit Criteria') %>%
  addMarkers(data = all_stn_sp, 
             lng = all_stn_sp@coords[,1], 
             lat = all_stn_sp@coords[,2], 
             popup = paste("<style> div.leaflet-popup-content {width:auto !important;}</style>",
                           lapply(rownames(all_stn_sp@data),
                                  function(row) {
                                    htmlTable::htmlTable(all_stn_sp@data[row,],
                                                         header = c("Station ID", "Station Description",
                                                                    names(all_stn_sp@data)[-c(1,2)]),
                                                         rnames = FALSE)
                                  })),
             group = 'All Stations Queried') %>%
  hideGroup('All Stations Queried') %>%
  addWMSTiles(baseUrl = 'https://smallscale.nationalmap.gov/arcgis/services/LandCover/MapServer/WMSServer?',
              group = "Land Use (NLCD 2011)",
              layers = "1",
              options = WMSTileOptions(version = '1.3.0',
                                       format = 'image/png',
                                       transparent = TRUE)) %>% 
  addWMSTiles(GetURL("USGSTopo"), 
              attribution = paste0("<a href='https://www.usgs.gov/'>",
                                   "U.S. Geological Survey</a> | ",
                                   "<ahref='https://www.usgs.gov/laws/policies_notices.html'>",
                                   "Policies</a>"),
              group = "USGS Topo", layers = "0") %>%
  addWMSTiles(GetURL("USGSHydroCached"), 
              group = "Hydrography", 
              options = WMSTileOptions(format = "image/png", 
                                       transparent = TRUE),
              layers = "0") %>%
  hideGroup("Hydrography") %>%
  addProviderTiles(providers$Esri.NatGeoWorldMap) %>%
  addLayersControl(baseGroups = c('Land Use (NLCD 2011)', 'USGS Topo', 'ESRI NatGEO World Map'),
                   overlayGroups = c('Stations That Fit Criteria', 'All Stations Queried', 'Hydrography'),
                   options = layersControlOptions(collapsed = FALSE)) %>%
  addEasyButton(easyButton(
    icon = "fa-globe",
    onClick = JS("function(btn, map){
                var groupLayer = map.layerManager.getLayerGroup('AgWQMA');
                map.fitBounds(groupLayer.getBounds());
                 }")))
map

```


A summary table of watershed land use by station that met data requirements for status or trend is presented in `r tbls("landUse", display="cite")`. The table is sorted in descending order by percent agriculture (% Ag), so stations located in watersheds with the highest percent agricultural land uses are at the top of the table.


```{r landuse-table, results="asis"}

stn_to_use<-c(unique(stns$Station_ID))

landuse<-stn_nlcd_df%>%
  filter(Station_ID %in% stn_to_use) %>%
  arrange(desc(PerAgWs))
colnames(landuse) <- c("Station ID", "Station Description", "Year", "Watershed Area (km^2^)",
                       "% Developed", "% Forest", "% Ag", "% Shrub/Grass", "% Other")
landuse <-landuse[, - 3]

save(landuse, file=paste0(Rdata_dir,"/", landuse_file))

knitr::kable(landuse, digits = 0, 
             padding = 2, row.names = FALSE, caption = tbls(name = "landUse", 
                                                            caption = "Summary table of watershed land use for stations with a status or trend result."))

```

## Water Quality Limited Stream Segments

A summary of Oregon's 2012 Integrated Report Assessment database and 303(d) list for parameters included in this report are shown in `r tbls(name = "wqLimited", display="cite")`. The table summarizes waterbodies that do not attain the applicable water quality criterion at the time of the assessment. Note that pH exceedances are values higher or lower than the given range.

```{r wq-limited, results="asis"}

wq_lim_whole <- extract_303d(df.all, wq_limited, input$select)
wq_lim_whole <- wq_lim_whole[,c('STREAM_LAK', 'LLID_STREA', 
                                'MILES', 'POLLUTANT', 'SEASON', 
                                'ASSESSME_1', 'CRITERIA', 
                                'LISTING_ST', 'TMDL_INFO')]
wq_lim_whole <- plyr::rename(wq_lim_whole, 
                             c('STREAM_LAK' = 'Waterbody',
                               'LLID_STREA' = 'LLID',
                               'ASSESSME_1' = 'Year Assessed',
                               'LISTING_ST' = 'Listing Status'))

wq_limited_df <- wq_lim_whole[, c('Waterbody', 'MILES', 'POLLUTANT', 'SEASON', 'Year Assessed', 'CRITERIA', 'Listing Status')]

names(wq_limited_df) <- c('Waterbody', 'Miles', 'Pollutant', 'Season', 'Year Assessed', 'Criteria', 'Listing Status')

wq_limited_df <- wq_limited_df %>% arrange(desc(Waterbody))

wq_limited_df$`Listing Status` <- revalue(wq_limited_df$`Listing Status`, 
                                          c("Cat 4A: Water quality limited, TMDL approved" = "Cat 4A",
                                            "Cat 5: Water quality limited, 303(d) list, TMDL needed" = "Cat 5",
                                            "TMDL approved" = "Cat 4A",
                                            "303(d)" = "Cat 5"))

# fix names and add italics
wq_limited_df$Pollutant <- gsub("[Ee]. [cC]oli", "_E. coli_", wq_limited_df$Pollutant)
wq_limited_df$Pollutant <- gsub("[Ee]terococcus", "_Enterococcus_", wq_limited_df$Pollutant)
wq_limited_df$Criteria <- gsub(".8 C", ".8 &deg;C", wq_limited_df$Criteria)
wq_limited_df$Criteria <- gsub(".0 degrees Celsius", ".0 &deg;C", wq_limited_df$Criteria)

knitr::kable(wq_limited_df, padding = 2, row.names = FALSE, caption = tbls(name = "wqLimited", caption = "Summary of Integrated Report listings for parameters included in this report. Table based on the approved (and partially disapproved) 2012 Integrated Report Listings by the EPA."))

```


## Seasonal Kendall Trend Analysis

For all monitoring stations with sufficient data (8 years or more), trending was performed using Seasonal Kendall trend analysis. Results are summarized in `r tbls(name = "seakenTable", display="cite")` below. The values in the N column represent the number of results for each analyte at each monitoring station and includes duplicate values; the slope refers to the slope of the trend line; the p-value represents the statistical significance of the trend (p <= 0.20 is significant and is defined in the 'significant' column); median represents the median value of all assessed results for each analyte at each monitoring station. If no table is visible, there were no monitoring stations with sufficient data to assess trends.


```{r Seasonal-Kendall, results="asis"}

SK <- SeaKen %>% filter(Station_ID %in% unique(stns$Station_ID)) %>% 
  filter(signif !=  "Insufficient data for trend analysis") %>% 
  filter(analyte != 'Dissolved oxygen saturation')

if(nrow(SK) > 0) {
  
  SK <- SK[, c(1, 2, 3, 4, 5, 8, 9)]
  SK <- SK[with(SK, order(analyte, Station_ID)),]
  
  SK$slope <- as.numeric(SK$slope)
  SK$pvalue <- as.numeric(SK$pvalue)

  colnames(SK) <- c("Station ID", "Analyte", "Slope", "p value", "Median", "N", "Significance Result")
  
  # fix names and add italics
  SK$Analyte <- gsub("[Ee]. [cC]oli", "_E. coli_", SK$Analyte)
  SK$Analyte <- gsub("[Ee]terococcus", "_Enterococcus_", SK$Analyte)

  knitr::kable(SK, padding = 2, format.args = list(scientific = FALSE), digits=3, row.names = FALSE, caption = tbls(name = "seakenTable", caption = "Seasonal Kendall trend results for each analyte at each monitoring station with at least eight years of data."))
}


```

## _E. coli_

```{r Ecoli, fig.height=6, fig.width=7, results='asis', eval.after="fig.cap", fig.cap=mapply(figs, cap.names, ecoli_captions)}

exc <- NULL
ecoli_stns <- NULL
ecoli <- NULL
cap.names <- list()
ecoli_captions <- list()

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  ecoli_trend <- trend %>%
    dplyr::filter(Analyte == "E. Coli")
  ecoli_trend <- c(unique(ecoli_trend$Station_ID))
}

ecoli_stat <- status %>%
  dplyr::filter(Analyte == "E. Coli")
ecoli_stat <- c(unique(ecoli_stat$Station_ID))

ecoli_stns <- unique(append(ecoli_trend, ecoli_stat))

if(length(ecoli_stns) > 0) {
  
  df.ecoli <- df.all[df.all$Analyte == 'E. Coli',]
  
  ecoli_list<- list()
  exc_list<- list()
  
  results_seaken <-SeaKen %>% filter(analyte == 'E. Coli')
  
  for(j in 1: length(ecoli_stns)) {
    new_data <- df.ecoli[df.ecoli$Station_ID == ecoli_stns[j],]
    ecoli_evaluate <- EvaluateEColiWQS(new_data)
    ecoli_eval <- attr(ecoli_evaluate, 'ex_df')
    ecoli_list[[j]] <- ecoli_evaluate
    exc_list[[j]] <- ecoli_eval
    
    trend_logic <- ifelse(grepl("Not Significant", 
                                results_seaken[results_seaken$Station_ID == ecoli_stns[j],'signif']),
                          FALSE,
                          ifelse(grepl("Need at least 8 years", 
                                       results_seaken[results_seaken$Station_ID == ecoli_stns[j],'signif']),
                                 FALSE, 
                                 TRUE))
    
    b <- plot.bacteria(new_data=ecoli_evaluate,
                       sea_ken_table=results_seaken ,
                       plot_trend = trend_logic,
                       plot_log = FALSE,
                       parm = unique(new_data$Analyte))
    
    print(b)
    ecoli_captions[[j]] <- paste0('Station ', ecoli_stns[j], ' _E. coli_ water quality status and/or trends.')
    cap.names[[j]] <- paste0("ecoli.",ecoli_stns[j])
    cat('\n\n')
  }
  
  ecoli <- rbind.fill(ecoli_list[])
  exc <- rbind.fill(exc_list[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  colnames(exc) <- c("Station ID", "Station Description", "Criteria", "Observations", "Exceedances", "Percent Exceedance")
  
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE,
               caption = tbls(name = "ecoliExcTable", 
                              caption = "_E. coli_ status. If sufficient data exists to calculate the geometric mean, it is included in the table."))
}  else {
  print("No monitoring stations have data to assess status and/or trend of _E. coli_.") 
}  

```

## _Enterococcus_ 

```{r Enterococcus, fig.height=6, fig.width=7, results='asis', fig.cap=mapply(figs, cap.names, entero_captions), eval.after="fig.cap"}

exc <- NULL
entero_stns <- NULL
entero <- NULL
cap.names <- list()
entero_captions <- list()

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  entero_trend <- trend %>%
    dplyr::filter(Analyte == "Enterococcus")
  entero_trend <- c(unique(entero_trend$Station_ID))
}

entero_stat <- status %>%
  dplyr::filter(Analyte == "Enterococcus")
entero_stat <- c(unique(entero_stat$Station_ID))

entero_stns <- unique(append(entero_trend, entero_stat))

if(length(entero_stns) > 0) {
  
  df.entero <- df.all[df.all$Analyte == 'Enterococcus',]
  
  entero_list<- list()
  exc_list<- list()
  entero_plots <-list()
  
  results_seaken <-SeaKen %>% filter(analyte == 'Enterococcus')
  
  for(j in 1: length(entero_stns)) {
    new_data <- df.entero[df.entero$Station_ID == entero_stns[j],]
    entero_evaluate <- EvaluateEnteroWQS(new_data)
    entero_eval <- attr(entero_evaluate, 'ex_df')
    entero_list[[j]] <- entero_evaluate
    exc_list[[j]] <- entero_eval
    
    trend_logic <- ifelse(grepl("Not Significant", 
                                results_seaken[results_seaken$Station_ID == entero_stns[j],'signif']),
                          FALSE,
                          ifelse(grepl("Need at least 8 years", 
                                       results_seaken[results_seaken$Station_ID == entero_stns[j],'signif']),
                                 FALSE, TRUE))
    
    
    b <- plot.bacteria(new_data=new_data,
                       sea_ken_table=results_seaken ,
                       plot_trend = trend_logic,
                       plot_log = FALSE,
                       parm = unique(new_data$Analyte))
    
    entero_plots[[j]] <- b
    
    print(entero_plots[[j]])

    entero_captions[[j]] <- paste0('Station ', entero_stns[j], ' _Enterococcus_ water quality status and/or trends.')
    cap.names[[j]] <- paste0("entero.",entero_stns[j])
    cat('\n\n')
    
  }
  
  entero <-rbind.fill(entero_list[])
  exc <-rbind.fill(exc_list[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  colnames(exc) <- c("Station ID", "Station Description", "Criteria", "Observations", "Exceedances", "Percent Exceedance")
  
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE,
               caption = tbls(name = "enterExcTable", 
                              caption = "_Enterococcus_ status. If sufficient data exists to calculate the geometric mean, it is included in this table."))
}  else {
  
  cat(paste0("A status and trend assessment was not made for *Enterococcus* because the marine water contact recreation use criteria do not apply in the ",agwqma,".")) 
} 

```

## Total Phosphorus

```{r Total-Phosphorus, fig.height=6, fig.width=7, results='asis', fig.cap=mapply(figs, cap.names, tp_captions), eval.after="fig.cap"}

exc <- NULL
tp_stn <- NULL
TP <- NULL
cap.names <- list()
tp_captions <- list()

if(!(trend == "No Stations Meet Trend Criteria")) {
  tp_stn<-trend %>%
    dplyr::filter(Analyte == "Total Phosphorus")
  tp_stn<-c(as.character(unique(tp_stn$Station_ID)))
}

tp_stat<-status %>%
  dplyr::filter(Analyte == "Total Phosphorus")
tp_stat <- c(as.character(unique(tp_stat$Station_ID)))

if(!is.null(tp_stn)){
  tp_stn <- unique(append(tp_stn, tp_stat))
  
} else {
  tp_stn <- tp_stat
}

if(length(tp_stn) > 0) {
  
  df.tp <- df.all[df.all$Analyte == 'Total Phosphorus',]
  results_seaken <-SeaKen %>% filter(analyte == 'Total Phosphorus')
  
  TP_list<- list()
  TP_exclist<- list()
  tp_plots<-list()
  
  
  for(j in 1: length(tp_stn)) {
    
    new_data <- df.tp[df.tp$Station_ID == tp_stn[j],]

    if (input$select %in% c('Owyhee','Malheur River','Burnt River','Powder-Brownlee','Hells Canyon','Lower Snake Asotin')) {
      # Snake River - Hells Canyon TMDL
      TP_evaluate <- EvaluateTP_SRHC(new_data, 
                                     selectWQSTP = 0.07)
    } else {
      
      TP_evaluate <- EvaluateTPWQS(new_data, 
                                   selectWQSTP = 0)
    }
    
    TP_eval <- attr(TP_evaluate, 'ex_df')
    TP_list[[j]] <- TP_evaluate
    TP_exclist[[j]] <- TP_eval
    
    trend_logic <-ifelse(grepl("Not Significant", 
                                 results_seaken[results_seaken$Station_ID == tp_stn[j],'signif']), 
                           FALSE,
                           ifelse(grepl("Need at least 8 years", 
                                        results_seaken[results_seaken$Station_ID == tp_stn[j],'signif']),
                                  FALSE,
                                  TRUE))
    
    if (input$select %in% c('Owyhee','Malheur River','Burnt River','Powder-Brownlee','Hells Canyon','Lower Snake Asotin')) {
      
      # Snake River - Hells Canyon TMDL
      b <- plot.TP(new_data=TP_evaluate,
                   sea_ken_table=results_seaken,
                   plot_trend = trend_logic,
                   selectWQSTP = 0.07,
                   parm = unique(TP_evaluate$Analyte))
    } else {
      
      b <- plot.TP(new_data=TP_evaluate,
                   sea_ken_table=results_seaken,
                   plot_trend = trend_logic,
                   selectWQSTP = 0,
                   parm = unique(TP_evaluate$Analyte))
    }
    
    
    tp_plots[[j]]<-b
    
    print(tp_plots[[j]])
    
    tp_captions[[j]] <- paste0('Station ', tp_stn[j], ' Total Phosphorus water quality status and/or trends.')
    cap.names[[j]] <- paste0("tp.",tp_stn[j])
    cat('\n\n')
  }
  
  TP <- rbind.fill(TP_list[])
  exc <- rbind.fill(TP_exclist[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  colnames(exc) <- c("Station ID","Station Description", "Min Year", "Max Year", 
                     "Observations", "Exceedances", "Percent Exceedance")
  
  if(all(is.na(exc$Exceedances))){
    exc <- exc[,1:5]
  }
  
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE, 
               caption = tbls(name = "tpExcTable", caption = " Total Phosphorus water quality trends."))
  
}

tp_exc <- exc

```


## Total Suspended Solids

```{r TSS, results = 'asis', fig.width = 7, fig.height = 6, fig.cap=mapply(figs, cap.names, tss_captions), eval.after="fig.cap"}

exc <- NULL
tss_stn <- NULL
TSS <- NULL
cap.names <- list()
tss_captions <- list()

if(!(trend == "No Stations Meet Trend Criteria")) {
  tss_stn<-trend %>%
    dplyr::filter(Analyte == "Total Suspended Solids")
  tss_stn<-c(unique(tss_stn$Station_ID))
}

tss_stat<-status %>%
  dplyr::filter(Analyte == "Total Suspended Solids")
tss_stat <- c(unique(tss_stat$Station_ID))

if(!is.null(tss_stn)) {
  tss_stn <- (unique(append(tss_stn, tss_stat)))
} else {
  tss_stn <- tss_stat
}

if(length(tss_stn) > 0){
  
  df.tss <- df.all[df.all$Analyte == 'Total Suspended Solids',]
  results_seaken <- SeaKen %>% filter(analyte == 'Total Suspended Solids')
  
  TSS_list<- list()
  TSS_exclist<- list()
  tss_plots<-list()
  
  for(j in 1: length(tss_stn)) {
    new_data <- df.tss[df.tss$Station_ID == tss_stn[j],]
    
    tmp_df <- new_data

    if (input$select %in% c('Owyhee','Malheur River','Burnt River','Powder-Brownlee','Hells Canyon','Lower Snake Asotin')) {
      
    # Snake River - Hells Canyon TMDL
      TSS_evaluate <- EvaluateTSS_SRHC(tmp_df, 
                                     TSS_target=50)
    } else {
      
      TSS_evaluate <- EvaluateTSSWQS(tmp_df, 
                                     selectWQSTSS = 0)
    }
    
    TSS_eval <- attr(TSS_evaluate, 'ex_df')
    TSS_list[[j]] <- TSS_evaluate
    TSS_exclist[[j]] <- TSS_eval
    
    ####
    
    trend_logic <-ifelse(grepl("Not Significant", 
                                 results_seaken[results_seaken$Station_ID == tss_stn[j],'signif']), 
                           FALSE,
                           ifelse(grepl("Need at least 8 years", 
                                        results_seaken[results_seaken$Station_ID == tss_stn[j],'signif']),
                                  FALSE,
                                  TRUE))
    
    if (input$select %in% c('Owyhee','Malheur River','Burnt River','Powder-Brownlee','Hells Canyon','Lower Snake Asotin')) {
      
      # Snake River - Hells Canyon TMDL
      b <- plot.TSS(new_data=TSS_evaluate,
                    sea_ken_table=results_seaken,
                    plot_trend = trend_logic,
                    selectWQSTSS = 50,
                    parm = paste0("Monthly Mean ",unique(TSS_evaluate$Analyte)))
    } else {

      b <- plot.TSS(new_data=TSS_evaluate,
                    sea_ken_table=results_seaken,
                    plot_trend = trend_logic,
                    selectWQSTSS = 0,
                    parm = unique(TSS_evaluate$Analyte))
    }
    
    
    tss_plots[[j]]<-b
    
    print(tss_plots[[j]])

    tss_captions[[j]] <- paste0('Station ', tss_stn[j], 
                              ' Total Suspended Solids water quality status and trends.')
    cap.names[[j]] <- paste0("tss.",tss_stn[j])
    cat('\n\n')
  }
  
  TSS<-rbind.fill(TSS_list[])
  exc<-rbind.fill(TSS_exclist[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100

  colnames(exc) <- c("Station ID","Station Description", "Min Year", "Max Year", 
                     "Observations", "Exceedances", "Percent Exceedance")

  if(all(is.na(exc$Exceedances))){
    exc <- exc[,1:5]
  }
  
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE, 
               caption = tbls(name = "tssExcTable", caption = "Total Suspended Solids observations."))

}

tss_exc <- exc

```


## pH

```{r pH, fig.height=6, fig.width=7, results='asis', fig.cap=mapply(figs, cap.names, pH_captions), eval.after="fig.cap"}

exc <- NULL
pH_stns <- NULL
pH <- NULL
cap.names <- list()
pH_captions <- list()

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  pH_trend <- trend %>%
    dplyr::filter(Analyte == "pH")
  pH_trend <- c(unique(pH_trend$Station_ID))
}

pH_stat <- status %>%
  dplyr::filter(Analyte == "pH")
pH_stat <- c(unique(pH_stat$Station_ID))

pH_stns <- unique(append(pH_trend, pH_stat))

if(length(pH_stns) > 0) {
  
  df.pH <- df.all[df.all$Analyte == 'pH',]
  results_seaken <- SeaKen %>% filter(analyte == 'pH')

  in_bentable <- (Ben_use_LU[Ben_use_LU$Station_ID %in% pH_stns, c('Station_ID', 'pH_benuse', 'pH_low', 'pH_high')])
  
  df.pH <- merge(df.pH,in_bentable, by.x = "Station_ID", by.y = "Station_ID")
  
  if(any(is.na(df.pH$pH_benuse) | is.na(df.pH$pH_low) | is.na(df.pH$pH_high)) | NROW(df.pH) == 0) {
    print("In order to assess against water quality standard, need to add pH beneficial uses to stations.csv for stations:")
      print(unique(df.pH[(is.na(df.pH$pH_benuse) | is.na(df.pH$pH_low) | is.na(df.pH$pH_high)),c("Station_ID")]))
    break
  }

  pH_list<- list()
  pH_exclist<- list()
  pH_plots <-list()

  for(j in 1: length(pH_stns)) {
    new_data <- df.pH[df.pH$Station_ID == pH_stns[j],]
    
    pH_evaluate <- EvaluatepHWQS(new_data = new_data,
                                 ph_crit_min = unique(new_data$pH_low),
                                 ph_crit_max = unique(new_data$pH_high),
                                 analyte_column = 'Analyte',
                                 station_id_column = 'Station_ID',
                                 station_desc_column = 'Station_Description',
                                 datetime_column = 'Sampled',
                                 result_column = 'Result')

    pH_eval <- attr(pH_evaluate, 'ex_df')
    pH_list[[j]] <- pH_evaluate
    pH_exclist[[j]] <- pH_eval
    
    trend_logic <-ifelse(grepl("Not Significant", 
                                 results_seaken[results_seaken$Station_ID == pH_stns[j],'signif']), 
                           FALSE,
                           ifelse(grepl("Need at least 8 years", 
                                        results_seaken[results_seaken$Station_ID == pH_stns[j],'signif']),
                                  FALSE,
                                  TRUE))
    
    # Tualatin stations that are not supposed to have trend
    if(pH_stns[j] %in% c('USGS-14202980', 'USGS-14206694', 'USGS-453004122510301', 'USGS-453030122560101', 'USGS-453040123065201')) {
      
      trend_logic <- FALSE }
    
    b <- plot.ph(new_data = pH_evaluate,
                 sea_ken_table = results_seaken,
                 plot_trend = trend_logic,
                 analyte_column = 'Analyte',
                 station_id_column = 'Station_ID',
                 station_desc_column = 'Station_Description',
                 datetime_column = 'Sampled',
                 result_column = 'Result',
                 datetime_format = '%Y-%m-%d %H:%M:%S',
                 ph_crit_min = unique(pH_evaluate$pH_low), 
                 ph_crit_max = unique(pH_evaluate$pH_high))
    
    pH_plots[[j]]<-b
    
    print(pH_plots[[j]])

    pH_captions[[j]] <- paste0('Station ', pH_stns[j], ' pH water quality status and/or trends.')
    cap.names[[j]] <- paste0("pH.",pH_stns[j])
    cat('\n\n')
  }
  
  pH <-rbind.fill(pH_list[])
  exc <-rbind.fill(pH_exclist[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
    
  colnames(exc) <- c("Station ID", "Station Description", "Min Date", "Max Date", "Observations", "Exceedances", "Percent Exceedance")
    
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE,
               caption = tbls(name = "pHExcTable", caption = "pH status."))
  
}

pH_exc <- exc

```


## Temperature

```{r Temperature, fig.height=6, fig.width=7, results='asis', fig.cap=mapply(figs, cap.names, temp_captions), eval.after="fig.cap"}

exc <- NULL
temp_stn <- NULL
temp <- NULL
cap.names <- list()
temp_captions <- list()

if(!(trend == "No Stations Meet Trend Criteria")) {
  temp_stn<-trend %>%
    dplyr::filter(Analyte == "Temperature")
  temp_stn<-c(as.character(unique(temp_stn$Station_ID)))
}

temp_stat<-status %>%
  dplyr::filter(Analyte == "Temperature")
temp_stat <- c(as.character(unique(temp_stat$Station_ID)))

if(!is.null(temp_stn)){
  temp_stn <- unique(append(temp_stn, temp_stat))
  
} else {
  temp_stn <- temp_stat
}

if(length(temp_stn) > 0) {
  
  if(any(!temp_stn %in% Ben_use_LU$Station_ID)){
    print("Before continuing, beneficial uses must be added for the following stations")
    print(temp_stn[!temp_stn %in% Ben_use_LU$Station_ID])
    View(stns[stns$Station_ID %in% temp_stn[!temp_stn %in% Ben_use_LU$Station_ID],])
    break
  }
  
  df.temp <- df.all[df.all$Analyte == 'Temperature',]
  results_seaken <-SeaKen %>% filter(analyte == 'Temperature')
  
  temp_list<- list()
  temp_exclist<- list()
  temp_plots<-list()
  
  for(j in 1: length(temp_stn)) {
    
    new_data <- df.temp[df.temp$Station_ID == temp_stn[j],]
    Temp_Benuse <- as.character((Ben_use_LU[Ben_use_LU$Station_ID == temp_stn[j], 'Temp_Benuse']))
    spwn_time <- as.character(Ben_use_LU[Ben_use_LU$Station_ID == temp_stn[j], 'spwn_time'])
    
    new_data$date <- as.Date(new_data$Sampled)
            
    temp_evaluate <- EvaluateTempWQS(sdadm_df = new_data,
                                     selectUse = Temp_Benuse[1],
                                     selectSpawning = spwn_time[1],
                                     station_id_column = 'Station_ID')
    
    # sort by station ID, parameters, and date/time
    temp_evaluate <- temp_evaluate[with(temp_evaluate, order(Station_ID, Analyte, Sampled)), ]
    rownames(temp_evaluate) <- 1:nrow(temp_evaluate)
    
    temp_eval <- attr(temp_evaluate, 'result_summary')
    temp_list[[j]] <- temp_evaluate
    temp_exclist[[j]] <- temp_eval
    
    trend_logic <-if(NROW(results_seaken[results_seaken$Station_ID == temp_stn[j],])>0){
      ifelse(grepl("Not Significant", 
                                 results_seaken[results_seaken$Station_ID == temp_stn[j],'signif']), 
                           FALSE,
                           ifelse(grepl("Need at least 8 years", 
                                        results_seaken[results_seaken$Station_ID == temp_stn[j],'signif']),
                                  FALSE,
                                  TRUE))
    } else {FALSE}
    
    b <- plot.Temperature(new_data = temp_evaluate,
                          sea_ken_table = results_seaken,
                          selectUse = Temp_Benuse[1],
                          selectSpawning = spwn_time[1],
                          station_id_column = 'Station_ID',
                          station_desc_column = 'Station_Description',
                          datetime_column = 'date',
                          datetime_format = '%Y-%m-%d',
                          plot_trend = trend_logic)
    
    temp_plots[[j]]<-b
    
    print(temp_plots[[j]])

    temp_captions[[j]] <- paste0('Station ', temp_stn[j], 
                              ' Temperature water quality status and/or trends.')
    cap.names[[j]] <- paste0("temp.",temp_stn[j])
    cat("\n\n")
  }
  
  temp <- rbind.fill(temp_list[])
  exc <- rbind.fill(temp_exclist[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  colnames(exc) <- c("Station ID","Station Description", "Time Period",
                     "Observations", " Exceedances", "Percent Exceedance")
  
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE, 
               caption = tbls(name = "tempExcTable", caption = " Temperature water quality status."))
  
} else {
  
    cat("There was insufficient data to calculate the seven day average daily maximum stream temperatures and make status and/or trend assessments for stream temperature.")

}

temp_exc <- exc

```


## Dissolved Oxygen

```{r Dissolved-Oxygen, fig.height=6, fig.width=7, results='asis', fig.cap=mapply(figs, cap.names, DO_captions), eval.after="fig.cap"}

exc <- NULL
DO_stns <- NULL
DO <- NULL
cap.names <- list()
DO_captions <- list()

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  DO_trend <- trend %>%
    dplyr::filter(Analyte == "Dissolved Oxygen")
  DO_trend <- c(unique(DO_trend$Station_ID))
}

DO_stat <- status %>%
  dplyr::filter(Analyte == "Dissolved Oxygen")
DO_stat <- c(unique(DO_stat$Station_ID))

DO_stns <- unique(append(DO_trend, DO_stat))

if(length(DO_stns) > 0) {
  
  df.DO <- df.all[df.all$Analyte == 'Dissolved Oxygen',]
  results_seaken <- SeaKen %>% filter(analyte == 'Dissolved Oxygen')

  in_bentable <- (Ben_use_LU[Ben_use_LU$Station_ID %in% DO_stns, c('Station_ID', 'DO_use', 'spwn_time')])
  
  df.DO <- merge(df.DO,in_bentable, by.x = "Station_ID", by.y = "Station_ID")
  
  if(any(is.na(df.DO$DO_use) | is.na(df.DO$spwn_time))) {
    print("In order to assess against water quality standard, need to add Dissolved Oxygen beneficial uses and spawning time periods to stations.csv for stations:")
      print(unique(df.DO[(is.na(df.DO$DO_use) | is.na(df.DO$spwn_time)),c("Station_ID")]))
    break
  }

  DO_list<- list()
  DO_exclist<- list()
  DO_plots <-list()

  for(j in 1: length(DO_stns)) {
    new_data <- df.DO[df.DO$Station_ID == DO_stns[j],]
    
    DO_sat_data <-df.all %>% 
      dplyr::filter(Analyte == 'Dissolved oxygen saturation') %>%
      dplyr::filter(Station_ID == DO_stns[j])

    DO_evaluate <- EvaluateDOWQS(new_data = new_data,
                                 DOsat = DO_sat_data,
                                 selectUseDO = unique(new_data$DO_use),
                                 selectSpawning = unique(new_data$spwn_time),
                                 analyte_column = 'Analyte',
                                 station_id_column = 'Station_ID',
                                 station_desc_column = 'Station_Description',
                                 datetime_column = 'Sampled',
                                 result_column = 'Result',
                                 datetime_format = '%Y-%m-%d %H:%M:%S')
    

    DO_eval <- attr(DO_evaluate, 'ex_df')
    DO_list[[j]] <- DO_evaluate
    DO_exclist[[j]] <- DO_eval
    
    trend_logic <-ifelse(grepl("Not Significant", 
                                 results_seaken[results_seaken$Station_ID == DO_stns[j],'signif']), 
                           FALSE,
                           ifelse(grepl("Need at least 8 years", 
                                        results_seaken[results_seaken$Station_ID == DO_stns[j],'signif']),
                                  FALSE,
                                  TRUE))
    
    # Tualatin stations that are not supposed to have trend
    if(DO_stns[j] %in% c('USGS-14202980', 'USGS-14206694', 'USGS-453004122510301', 'USGS-453030122560101', 'USGS-453040123065201')) {
      
      trend_logic <- FALSE }
    
    b <- plot.DO(new_data = DO_evaluate,
                 selectUseDO = unique(DO_evaluate$DO_use),
                 sea_ken_table = results_seaken,
                 plot_trend = trend_logic,
                 selectSpawning = unique(DO_evaluate$spwn_time),
                 analyte_column = 'Analyte',
                 station_id_column = 'Station_ID',
                 station_desc_column = 'Station_Description',
                 datetime_column = 'Sampled',
                 result_column = 'Result',
                 datetime_format = '%Y-%m-%d %H:%M:%S',
                 parm = 'Dissolved Oxygen')

    
    DO_plots[[j]]<-b
    
    print(DO_plots[[j]])

    DO_captions[[j]] <- paste0('Station ', DO_stns[j], ' Dissolved Oxygen water quality status and/or trends.')
    cap.names[[j]] <- paste0("DO.",DO_stns[j])
    cat('\n\n')
  }
  
  DO <-rbind.fill(DO_list[])
  exc <-rbind.fill(DO_exclist[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
    
  colnames(exc) <- c("Station ID", "Station Description", "Observations", "Exceedances", 
                     "Meets b/c %Sat", "Min Year", "Max Year", "Percent Exceedance")
    
  knitr::kable(exc, padding = 2, digits = 1, row.names = FALSE,
               caption = tbls(name = "doExcTable", caption = "Dissolved Oxygen status."))
  
}

DO_exc <- exc

```

# Summary 

```{r Summary-map1, results = 'asis', eval = word_output & !(split_param_summary), fig.cap=figs(name="Summary_map1", caption="Summary of stations that fit the criteria for status and trend analysis. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(paste0("Figures/",station_summary_map1_file))

```


```{r Summary-map2, results = 'asis', eval = word_output & !(split_param_summary), fig.cap=figs(name="Summary_map2", caption="Summary of stations that fit the criteria for status and trend analysis. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(paste0("Figures/",station_summary_map2_file))

```


```{r DO-summary-map, results = 'asis', eval = word_output & split_param_summary, fig.cap=figs(name="DO_map", caption="Summary of stations that fit the criteria for status and trend analysis for dissolved oxygen. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(paste0("Figures/",station_summary_map_DO_file))

```



```{r Ecoli-summary-map, eval = word_output & split_param_summary, results='asis', fig.cap=figs(name="Ecoli_map", caption="Summary of stations that fit the criteria for status and trend analysis for E coli. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets. Clusters of stations (grey circles located on the western margin of the study area) had insufficient data to determine status and trends for E. coli.")}

knitr::include_graphics(path = paste0("Figures/",station_summary_map_ecoli_file))

```


```{r Entero-summary-map, eval = word_output & split_param_summary, results='asis', fig.cap=figs(name="Entero_map", caption="Summary of stations that fit the criteria for status and trend analysis for Enterococcus. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(path = paste0("Figures/",station_summary_map_entero_file))

```

```{r Temp-summary-map, eval = word_output & split_param_summary, results='asis', fig.cap=figs(name="Temperature_map", caption="Summary of stations that fit the criteria for status and trend analysis for temperature. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(path = paste0("Figures/",station_summary_map_temp_file))

```

```{r ph-summary-map, eval = word_output & split_param_summary, results='asis', fig.cap=figs(name="pH_map", caption="Summary of stations that fit the criteria for status and trend analysis for pH. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(path = paste0("Figures/",station_summary_map_pH_file))

```


```{r TP-summary-map, eval = word_output & split_param_summary, results='asis', fig.cap=figs(name="TP_map", caption="Summary of stations that fit the criteria for trend analysis for Total Phosphorus.  Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(path = paste0("Figures/",station_summary_map_tp_file))

```

```{r TSS-summary-map, results = 'asis', eval = word_output & split_param_summary, fig.cap=figs(name="TSS_map", caption="Summary of stations that fit the criteria for status and trend analysis for Total Suspended Solids. Trend was determined by significant trends associated with long-term datasets.")}

knitr::include_graphics(path = paste0("Figures/",station_summary_map_tss_file))

```

Summary of stations that fit the criteria for status and/or trend analysis. One or more exceedances within the last three years of available data defined whether a station was 'Meeting' or 'Not Meeting'. Trend was determined by significant trends associated with long-term datasets.

```{r parm-summary-table, results = 'asis'}

stns_param_summary <-  parm_summary(stns = stns[,c(1:4)],
                            ecoli = ecoli,
                            entero = entero,
                            pH = pH,
                            DO = DO,
                            temp = temp,
                            tp = TP,
                            tss = TSS,
                            SeaKen = SeaKen,
                            status.years = status_years,
                            status = status,
                            trend = trend)


# create a shapefile
stns_param_summary_shp <- stns_param_summary %>%
                  #dplyr::select(-c(TP_S, TSS_S)) %>%
                  dplyr::rename(Name=Station_Description, 
                                Latitude=DECIMAL_LAT, 
                                Longitude=DECIMAL_LONG)

coordinates(stns_param_summary_shp)=~Longitude+Latitude

# NAD83 : EPSG:4269 <- This is assumed for DATUM
proj4string(stns_param_summary_shp) <- CRS("+init=epsg:4269")

# sort by station ID
stns_param_summary_shp <- stns_param_summary_shp[order(stns_param_summary_shp$Station_ID),]

# write the shapefile
writeOGR(obj=stns_param_summary_shp, dsn=GIS_dir, layer="station_param_summary", driver="ESRI Shapefile", overwrite_layer=TRUE)

# format for table
stns_param_summary_tbl <- dplyr::select(stns_param_summary, -c(DECIMAL_LAT, DECIMAL_LONG))

colnames(stns_param_summary_tbl) <- c("Station ID", "Station Description",
                                      "DO Status", "DO Trend",
                                      "_E. coli_  Status", "_E. coli_ Trend", 
                                      "_Enterococcus_ Status", "_Enterococcus_ Trend",
                                      "pH Status", "pH Trend", 
                                      "Temperature Status", "Temperature Trend",
                                      "TP Status","TP Trend", 
                                      "TSS Status","TSS Trend")

save(stns_param_summary, file=paste0(Rdata_dir,"/", stns_param_summary_file))

knitr::kable(stns_param_summary_tbl, 
             padding = 2, digits = 3,
             row.names = FALSE,
             caption = tbls(name = "parmSumTable", 
                            caption = "Summary of monitoring stations status and trend, where 'Exceeds' represents a single exceedance of the water quality standard or TMDL target within the last two whole years. Note: DO = dissolved oxygen, TP = total phosphorus, TSS = total suspended solids."))

```

```{r parm-summary-map-html, results = 'asis', eval = !(word_output), fig.width=8.5, fig.height=7}

library(base64enc)
 
statusColor <- function(statusColumn) {
  sapply(statusColumn, function(x){
    if(x == "Meets"){
      "green"
    } else if(x == "Exceeds"){
      "orange"
    } else {"lightgray"}
  }, USE.NAMES = FALSE)
}

trendIcon <- function(trendColumn) {
  sapply(trendColumn, function(x){
    if(x == "Improving"){
      "glyphicon-arrow-up"
    } else if(x == "Degrading"){
      "glyphicon-arrow-down"
    } else if(x == "No Sig Trend"){
      "glyphicon-minus"
    } else if(x == "Steady") {
      "glyphicon-arrow-right"
    }
    else {""}
  }, USE.NAMES = FALSE)
}

# Create function to pull the selected parameter's status and trend and create a popup table for the station. This function is called on the click of a station marker in the parameter summary map.
popupTable <- function(param){
  table <- paste("<style> div.leaflet-popup-content {width:auto !important;}</style>",
                    lapply(rownames(stns_param_summary), 
                           function(row) {
                             htmlTable::htmlTable(stns_param_summary[row,c("Station_ID", "Station_Description",
                                                                           paste0(param, "_S"), paste0(param, "_T"))],
                                                  header = c("Station ID", "Station Description",
                                                             paste0(param, " Status"), paste0(param, " Trend")),
                                                  rnames = FALSE)
                           }))
  return(table)
}


agwqma_shp_buff <- gBuffer(agwqma_all_shp[agwqma_all_shp$PlanName == input$select,], width=500)
agwqma_shp_buff <- spTransform(agwqma_shp_buff, CRS("+init=epsg:4326"))
agwqma_shp <- spTransform(agwqma_shp, CRS("+init=epsg:4326"))
wql_streams_shp <- spTransform(wql_streams_shp, proj4string(agwqma_shp_buff))
wql_streams_clip <- raster::intersect(wql_streams_shp, agwqma_shp_buff)

lgnd <- base64enc::base64encode(paste0(project_dir, "/Figures/", "Parm_Summary_mapLegend.png"))

leaflet(agwqma_shp) %>%
  addWMSTiles(GetURL("USGSTopo"),
              attribution = paste0("<a href='https://www.usgs.gov/'>",
                                   "U.S. Geological Survey</a> | ",
                                   "<ahref='https://www.usgs.gov/laws/policies_notices.html'>",
                                   "Policies</a>"),
              group = "USGS Topo", layers = "0") %>%
  addProviderTiles(providers$Esri.NatGeoWorldMap, group = "NatGeo World Map") %>%
  addWMSTiles(GetURL("USGSHydroCached"),
              group = "Hydrography",
              options = WMSTileOptions(format = "image/png",
                                       transparent = TRUE),
              layers = "0") %>%
  addPolygons(fill=FALSE, group = "AgWQMA") %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`Ecoli_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`Ecoli_S`)),
                    popup = popupTable("Ecoli"),
                    group = "Ecoli"
  ) %>%
  addPolylines(data = wql_streams_clip[wql_streams_clip$POLLUTANT == "E. Coli",], popup = ~paste("<b>",STREAM_NAM, "</b><br>", LISTING_ST),
               weight = 2, opacity = 0.7, fill = FALSE, color = "#800000", group = "Ecoli") %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`Entero_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`Entero_S`)),
                    popup = popupTable("Entero"),
                    group = "Enterococcus"
  ) %>%
  addPolylines(data = wql_streams_clip[wql_streams_clip$POLLUTANT == "Enterococcus",], popup = ~paste("<b>",STREAM_NAM, "</b><br>", LISTING_ST),
               weight = 2, opacity = 0.7, fill = FALSE, color = "#800000", group = "Enterococcus") %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`Temp_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`Temp_S`)),
                    popup = popupTable("Temp"),
                    group = "Temperature"
  ) %>% 
  addPolylines(data = wql_streams_clip[wql_streams_clip$POLLUTANT == "Temperature",], popup = ~paste("<b>",STREAM_NAM, "</b><br>", LISTING_ST),
               weight = 2, opacity = 0.7, fill = FALSE, color = "#800000", group = "Temperature") %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`pH_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`pH_S`)),
                    popup = popupTable("pH"),
                    group = "pH"
  ) %>% 
  addPolylines(data = wql_streams_clip[wql_streams_clip$POLLUTANT == "pH",], popup = ~paste("<b>",STREAM_NAM, "</b><br>", LISTING_ST),
               weight = 2, opacity = 0.7, fill = FALSE, color = "#800000", group = "pH") %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`DO_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`DO_S`)),
                    popup = popupTable("DO"),
                    group = "Dissolved Oxygen"
  ) %>%
  addPolylines(data = wql_streams_clip[wql_streams_clip$POLLUTANT == "Dissolved Oxygen",], popup = ~paste("<b>",STREAM_NAM, "</b><br>", LISTING_ST),
               weight = 2, opacity = 0.7, fill = FALSE, color = "#800000", group = "Dissolved Oxygen") %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`TP_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`TP_S`)),
                    popup = popupTable("TP"),
                    group = "Total Phosphorus"
  ) %>%
  addAwesomeMarkers(data = stns_param_summary,
                    lat = stns_param_summary$DECIMAL_LAT,
                    lng = stns_param_summary$DECIMAL_LONG,
                    icon = awesomeIcons(icon = trendIcon(stns_param_summary$`TSS_T`),
                                        iconColor = 'black',
                                        library = 'glyphicon',
                                        markerColor = statusColor(stns_param_summary$`TSS_S`)),
                    popup = popupTable("TSS"),
                    group = "Total Suspended Solids"
  ) %>%
  addLayersControl(baseGroups = c("Dissolved Oxygen", "Ecoli", "Enterococcus", "Temperature", "pH", 
                                  "Total Phosphorus", "Total Suspended Solids"),
                   overlayGroups = c("NatGeo World Map", "Hydrography"), options = layersControlOptions(collapsed = FALSE)) %>%
  hideGroup(c("Hydrography", "NatGeo World Map")) %>% 
  addControl(position = "bottomleft", 
             html = sprintf('<html><body><div style="opacity:0.8">
                                        <img width="350" height="175" src="data:image/png;base64,%s">
                            </div></body></html>', lgnd)) %>%
  addEasyButton(easyButton(
    icon = "fa-globe",
    onClick = JS("function(btn, map){
                var groupLayer = map.layerManager.getLayerGroup('AgWQMA');
                map.fitBounds(groupLayer.getBounds());
                 }")))

```

# Conclusions

```{r conclusions-setup}

colnames(stns_param_summary) <- c("Station_ID", "Station_Description",
                                  "DEC_LAT","DEC_LONG",
                                  "DO_S", "DO_T",
                                  "Ecoli_S", "Ecoli_T", 
                                  "Entero_S", "Entero_T",
                                  "pH_S", "pH_T", 
                                  "Temp_S", "Temp_T",
                                  "TP_S","TP_T", 
                                  "TSS_S","TSS_T")

# Text for conclusions. Use auto conclusion function or make your own text
conclusions.DO <- con.auto(df=stns_param_summary, status_column="DO_S", trend_column="DO_T")
conclusions.Ecoli <- con.auto(df=stns_param_summary, status_column="Ecoli_S", trend_column="Ecoli_T")
conclusions.Entero <- con.auto(df=stns_param_summary, status_column="Entero_S", trend_column="Entero_T")
conclusions.pH <- con.auto(df=stns_param_summary, status_column="pH_S", trend_column="pH_T")
conclusions.Temp <- con.auto(df=stns_param_summary, status_column="Temp_S", trend_column="Temp_T")
conclusions.TP <- con.auto(df=stns_param_summary, status_column="TP_S", trend_column="TP_T")
conclusions.TSS <- con.auto(df=stns_param_summary, status_column="TSS_S", trend_column="TSS_T")

# Text for additional conclusions
conclusions.add.txt <- c("The text for an additional conclusions goes here.",
                         "The text for a second additional conclusions goes here.",
                         "third, etc.")

# Put everything together into a dataframe
conclusions.param.df <- data.frame(AgArea=rep(input$select,7),
                                   topic=c("DO","Ecoli","Entero","pH","Temp","TP","TSS"),
                                   conclusion=c(conclusions.DO,
                                                conclusions.Ecoli,
                                                conclusions.Entero,
                                                conclusions.pH, 
                                                conclusions.Temp, 
                                                conclusions.TP, 
                                                conclusions.TSS))

conclusions.add.df <- data.frame(AgArea=rep(input$select,length(conclusions.add.txt)),
                                 topic=rep("Add_conc", length(conclusions.add.txt)), 
                                 conclusion=conclusions.add.txt)

# Remove any existing conclusions
Conc_LU <- Conc_LU[!(Conc_LU$AgArea %in% input$select),]

# Update the Conclusions Lookup
Conc_LU <- rbind(Conc_LU, conclusions.param.df, conclusions.add.df)

# Write to csv (overwrites existing)
write.table(Conc_LU, file = paste0(project_dir,"/Lookups/Conclusions_LU.csv"), row.names = FALSE, sep = ",")

```

**What is the overall status or trends in water quality?**

* *Dissolved Oxygen*: `r conclusions.DO`
* *E. coli*: `r conclusions.Ecoli`
* *Enterococcus*: `r conclusions.Entero`
* *pH*: `r conclusions.pH`
* *Temperature*: `r conclusions.Temp`
* *Total Phosphorus*: `r conclusions.TP`
* *Total Suspended Solids*: `r conclusions.TSS`


**Additional Conclusions:**

`r paste0("* ",conclusions.add.txt,"\n", collapse="")`


# Citations

Helsel, D.R. and R. M. Hirsch, 2002. Statistical Methods in Water Resources Techniques of Water Resources Investigations, Book 4, chapter A3. U.S. Geological Survey. 522 pages.

Hirsch, R.M. and J.R. Slack. 1984. A nonparametric trend test for seasonal data with serial dependence. *Water Resources Research* 20(6):727-732.

Hirsch, R.M., J.R. Slack and R.A. Smith. 1982. Techniques of trend analysis for monthly water quality data. *Water Resources Research* 18(1):107-121.

Homer, C.G., Dewitz, J.A., Yang, L., Jin, S., Danielson, P., Xian, G., Coulston, J., Herold, N.D., Wickham, J.D., and Megown, K., 2015. Completion of the 2011 National Land Cover Database for the conterminous United States-Representing a decade of land cover change information. *Photogrammetric Engineering and Remote Sensing*, 81(5):345-354.

Mann, H. B., 1945, Nonparametric test against trend: *Econometrica* 13, 245-259.

McKay, L., Bondelid, T., Dewald, T., Johnston, J., Moore, R., and Rea, A. 2012. NHDPlus Version 2:User Guide (Data Model Version 2.1). Available from http://www.horizon-systems.com/NHDPlus/NHDPlusV2_documentation.php.


Oregon Department of Environmental Quality, 2013. Quality Manual. DEQ91-LAB-0006-LQM Version 8.2.

U.S. Environmental Protection Agency. 2016. National Rivers and Streams Assessment 2008-2009. Available from U.S. EPA website: http://www.epa.gov/national-aquatic-resource-surveys/data-national-aquatic-resource-surves, accessed `r format(ymd(input$dates[2]), format="%B %d, %Y")`.

U.S. Geological Survey, 2016, National Water Information System data available on the World Wide Web (USGS Water Data for the Nation), accessed `r format(ymd(input$dates[2]), format="%B %d, %Y")`, at URL [http://waterdata.usgs.gov/nwis/].

# Appendix

```{r appendix, results="asis"}

org_summary <- summarizeByOrg(df.all)

# clean up column names
colnames(org_summary) <- c("Organization",	"Observations",	"Unique Stations",	"NA observations",	"Unique Comments")

# org summary by station and analyte
fit_criteria <- rbind(status[,c("Station_ID", "Analyte")], trend[,c("Station_ID", "Analyte")])

fit_criteria <- unique(fit_criteria[c("Station_ID", "Analyte")])

org_summary_station <- fit_criteria %>%
  dplyr::left_join(df.all,by=c("Station_ID", "Analyte"))  %>%
  dplyr::group_by(Station_ID, Analyte) %>%
  dplyr::summarise('Sampling Organizations' = paste(sort(unique(Client)), collapse = ", ")) %>%
  as.data.frame()

colnames(org_summary_station)[1] <- "Station ID"
colnames(status)[1] <- "Station ID"
colnames(trend)[1] <- "Station ID"
colnames(stns_by_year)[1] <- "Station ID"

# Add italics to E. coli and Enterococcus
org_summary_station$Analyte <- gsub("[Ee]. [cC]oli", "_E. coli_", org_summary_station$Analyte)
org_summary_station$Analyte <- gsub("[Ee]terococcus", "_Enterococcus_", org_summary_station$Analyte)
status$Analyte <- gsub("[Ee]. [cC]oli", "_E. coli_", status$Analyte)
status$Analyte <- gsub("[Ee]terococcus", "_Enterococcus_", status$Analyte)
trend$Analyte <- gsub("[Ee]. [cC]oli", "_E. coli_", trend$Analyte)
trend$Analyte <- gsub("[Ee]terococcus", "_Enterococcus_", trend$Analyte)
stns_by_year$Analyte <- gsub("[Ee]. [cC]oli", "_E. coli_", stns_by_year$Analyte)
stns_by_year$Analyte <- gsub("[Ee]terococcus", "_Enterococcus_", stns_by_year$Analyte)

knitr::kable(org_summary, padding = 2, digits = 1, row.names = FALSE, caption = tbls(name = "AppendixorgSumTable", caption = "Summary table of all unique organizations that were queried; note that organizations included in this table may or may not have had data sufficient for status and/or trends analysis and therefore may not be included in this report."))

knitr::kable(org_summary_station, padding = 2, digits = 1, row.names = FALSE, caption = tbls(name = "AppendixorgSumbyStation", caption = "Summary of all unique organizations that collected data at each station for each analyte that had a status and/or trend result."))

knitr::kable(status, padding = 2, digits = 1, row.names = FALSE, caption = tbls(name = "AppendixstatusTable", caption = "Number of observations per year for monitoring stations that fit the criteria to assess status."))

knitr::kable(trend, padding = 1, digits = 1, row.names = FALSE, caption = tbls(name = "AppendixtrendTable", caption = "Number of observations per year for monitoring stations that fit the criteria to assess trend."))

knitr::kable(stns_by_year, padding = 1, digits = 1, row.names = FALSE, caption = tbls(name = "AppendixstnByYrTable", caption = "All monitoring stations that were queried and the number of results per year during the query period."))

```

