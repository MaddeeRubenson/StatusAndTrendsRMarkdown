---
title: '<img src="Figures/LogoColorRegular.jpg" style="float: right;width: 80px; "/>Oregon DEQ Water Quality Status and Trends report for the Molalla-Pudding French Prairie North Santiam AgWQ Management Area'
date: March 2018
output:
  word_document:
    fig_caption: yes
    reference_docx: //deqhq1/WQNPS/Agriculture/Status_and_Trend_Analysis/R_support_files/Report_Template.docx
    toc: yes
  html_document:
    mode: selfcontained
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
always_allow_html: yes
---

```{r setup-packages-functions, include=FALSE}

library(knitr)
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE, 
                      warning=FALSE, 
                      error = FALSE,
                      cache = FALSE,
                      results = 'hide',
                      include = TRUE,
                      fig.keep='all',
                      fig.path='Figures/'
                      )

library(RODBC)
library(RCurl)
library(XML)
library(dataRetrieval)
library(plyr)
library(sp)
library(rgdal)
library(raster)
library(rgeos)
library(DT)
library(wq)
library(chron)
library(reshape)
library(reshape2)
library(ggplot2)
library(ggthemes)
library(zoo)
library(spatialEco)
library(dplyr)
library(lubridate)
library(ggthemes)
library(captioner)
library(plyr)
library(tidyr)
library(leaflet)

source('functions/Rmarkdown_query.R')
source('functions/01_DataQuery.R')
source("functions/funHelpers.R")
source("functions/funClean.R")
source("functions/funSeaKen.R")
source("functions/funPlots.R")
source('functions/TualatinR_Allocations.R')

tbls  <- captioner(prefix="**Table")
figs <- captioner(prefix="  \n**Figure")
```

```{r inputs}

# agwqma, query_dates, and project_dir are different for every Report. Note 'agwqma' must be named exactly 
# how it is named in the agwqma shapefile ('agwqma_shp').
agwqma <- "Molalla-Pudding French Prairie North Santiam"
query_dates <- c("2000-01-01", "2018-03-01")
project_dir <- "//deqhq1/WQNPS/Agriculture/Status_and_Trend_Analysis/Molalla-Pudding French Prairie North Santiam/2018/StatusAndTrendsRMarkdown"

# Set to TRUE if knitting a word document
word_output <- TRUE

# Everything below here should not change
support_files_dir <- "//deqhq1/WQNPS/Agriculture/Status_and_Trend_Analysis/R_support_files"
Rdata_dir <- paste0(project_dir,"/RData")
GIS_dir <- paste0(project_dir,"/GIS")

# Name of input map files
landuse_map_file <- paste0(gsub(" ", "_", agwqma), "_landuse_map.png")
station_map_file <- paste0(gsub(" ", "_", agwqma), "_station_map.png")
station_summary_map_DO_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_DO.png")
station_summary_map_pH_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_pH.png")
station_summary_map_temp_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_temp.png")
station_summary_map_ecoli_file <- paste0(gsub(" ", "_", agwqma), "_station_summary_map_ecoli.png")


# Name of output files
df_all_raw_file <- paste0(gsub(" ", "_", agwqma), "_df_all_raw_",paste(query_dates, collapse = "."), ".Rdata")
df_all_clean_file <- paste0(gsub(" ", "_", agwqma), "_df_all_clean_",paste(query_dates, collapse = "."), ".Rdata")
landuse_file <- paste0(gsub(" ", "_", agwqma), "_landuse.Rdata")
stns_file <- paste0(gsub(" ", "_", agwqma), "_stns.Rdata")
status_file <- paste0(gsub(" ", "_", agwqma), "_status.Rdata")
trend_file <- paste0(gsub(" ", "_", agwqma), "_trend.Rdata")
stns_param_summary_file <- paste0(gsub(" ", "_", agwqma), "_station_param_summary.Rdata")

input <- list(action_button = c(0))
input$select <- agwqma
input$dates <- query_dates
input$parms <- c('Total Phosphorus',
                 'Total Suspended Solids',
                 'Total Suspended Solids',
                 'Bacteria',
                 'Temperature',
                 'pH',
                 'Dissolved Oxygen',
                 'Total Nitrogen')

input$db <- c('DEQ', 'Water Quality Portal')

# Check if the local GIS directory exists
if (!file.exists(paste0(project_dir,"/GIS"))) {
    dir.create(paste0(project_dir,"/GIS"))
}

# Check if the local RData directory exists
if (!file.exists(paste0(project_dir,"/RData"))) {
    dir.create(paste0(project_dir,"/RData"))
}

# Check if the local Figures directory exists
if (!file.exists(paste0(project_dir,"/Figures"))) {
    dir.create(paste0(project_dir,"/Figures"))
}

```

```{r lookup-imports}

# import github Lookups
BC_LU <- read.csv("Lookups/BC_LU.csv")
Conc_LU <- read.csv("Lookups/Conclusions_LU.csv", na.strings = c("", "NA"))
OAR_LU <- read.csv("Lookups/OAR_LU.csv")
Ben_use_LU <- read.csv("Lookups/stations.csv", na.strings = c("", "NA"))
wq_limited <- read.csv('Lookups/wq_limited_2012_df_temp_bact_ph_DO_TP_Sediment.csv')
HUClist <- read.csv('Lookups/PlanHUC_LU.csv')
stations_huc <- read.csv('Lookups/station_wbd_12132016.csv')
ph_crit <- read.csv('Lookups/PlanOWRDBasinpH_LU.csv')
lu_parms <- read.csv('Lookups/WQP_Table3040_Names.csv', stringsAsFactors = FALSE)

ph_crit <- merge(ph_crit, HUClist, by.x = 'plan_name', by.y = 'PlanName', all.x = TRUE)

# import GIS features
agwqma_shp <- readOGR(dsn = support_files_dir, layer = 'ODA_AgWQMA', integer64="warn.loss", verbose = FALSE)
tribal_lands_shp <- readOGR(dsn = support_files_dir, layer = 'tl_2017_or_aiannh', integer64="warn.loss", verbose = FALSE)
#hucs_shp <- readOGR(dsn = support_files_dir, layer = 'WBD_HU8', integer64="warn.loss", verbose = FALSE)

# Import other data frames
load(paste0(support_files_dir,'/NLCD2011_OR.Rdata'))
load(paste0(support_files_dir,'/OR_cats.Rdata'))

```

```{r Query, include=FALSE}

if(file.exists(file=paste0(Rdata_dir,"/",df_all_raw_file))) {
  
  print("loading existing df.all")
  load(file=paste0(Rdata_dir,"/",df_all_raw_file))
  
} else {
  
  df.all <- query(select =  input$select,
                  parms = input$parms,
                  dates = input$dates,
                  db = input$db)
  
  save(df.all, file=paste0(Rdata_dir,"/",df_all_raw_file))
}


```

```{r Clean-df.all, include=FALSE}

if(file.exists(file=paste0(Rdata_dir,"/",df_all_clean_file))) {
  
  print("loading existing cleaned df.all")
  load(file=paste0(Rdata_dir,"/",df_all_clean_file))
  
} else {
  
  print("cleaning df.all")
  
  # remove data collected on tribal nation land or tribal trust land
  df.all <-df.all[df.all$Station_ID %in% Stations_in_poly(df.all, tribal_lands_shp, outside=TRUE),]
  
  # grab station 10344 before it gets clipped
  station10344 <- filter(df.all, Station_ID == 10344)
  
  # remove stations outside the agwqma
  df.all <- clipToPlanArea(df.all, agwqma_shp, input$select)
  
  # add station 10344 back in
  df.all <- rbind(df.all, station10344)
  
  # Reconcile the same ODEQ stations that have different IDs in WQP and DEQ Databases
  # The Station ID will be named the same as LASAR
  df.all$Station_ID <- gsub("OREGONDEQ-", "", df.all$Station_ID)
  df.all$Station_ID <- gsub("-ORDEQ", "", df.all$Station_ID)
  df.all$Station_ID <- gsub("21ORBCH-", "", df.all$Station_ID)
  
  # Reconcile Stations with the same ID but have different Lat/Longs 
  df.all <- remove_stn_dups(df.all)
  
  # Remove obervations that are the same from two databases
  # Same is defined as having the same station ID, Sample Date/time, and Analyte
  # Note the WQP field 'StatisticalBaseCode' is a code that identifies if the result 
  # is a calculated value like Daily Max or 7DADM. This needs to be incorporated somehow.
  df.all$IDSA <- paste(df.all$Station_ID,df.all$Sampled,df.all$Analyte, sep=" ")
  df.all <- df.all[!duplicated(df.all[c("IDSA")] ), ]
  
  
  ## Add snapped stations
  #df.all <- Snapped_Stations(df.all)
  
  df.all$Result <- clean(df.all$Result)
  df.all$Result <- suppressWarnings(as.numeric(df.all$Result))
  df.all <- MRLhandling(df.all)
  
  if ("Fecal Coliform" %in% df.all$Analyte) {
    df.all <- update_fc2ec(df.all)
  }
  
  df.all <- remove_QAfail(df.all)
  
  if (any('Temperature' %in% df.all$Analyte)) {
    
    tempStns <- temp_sufficiency_analysis(df.all)
    
    qc.1.pass <- filter(attributes(tempStns)$day_test, result == "pass")
    qc.2.pass <- filter(attributes(tempStns)$month_test, result == "pass")
    qc.3.pass <- filter(attributes(tempStns)$year_test, result == "pass")
    qc.1.stn <- filter(attributes(tempStns)$day_test, result == "pass")$Station_ID
    qc.2.stn <- filter(attributes(tempStns)$month_test, result == "pass")$Station_ID
    qc.3.stn <- filter(attributes(tempStns)$year_test, result == "pass")$Station_ID
    
    qc.1.pass$IDD <- paste0(qc.1.pass$Station_ID," ",qc.1.pass$date)
    
    df.all.temp <- df.all %>% 
      filter(Analyte == "Temperature")  %>%
      mutate(date = date(Sampled)) %>%
      mutate(IDD = paste0(Station_ID," ",date)) %>%
      merge(qc.1.pass[,c("result", "IDD")], by=c("IDD"), all=FALSE)

    
    df.all.temp$Result <- convert_temp_F_C(df.all.temp, result_column_name="Result", unit_column_name="Unit")
    df.all.temp$Unit <- "Celsius"
    
    df.sdadm <- Calculate.sdadm(df.all.temp, "Result", "Station_ID", "Sampled", '%Y-%m-%d %H:%M:%S')
    
    # Remove NAs
    df.sdadm <- df.sdadm[!(is.na(df.sdadm$sdadm)),]
    
    df.sdadm$IDD <- paste0(df.sdadm$Station_ID," ",df.sdadm$date)
    
    # Attempt at pulling the other df fields for each daily sample so it can be added back to sdadm
    df.all.temp.fields <- df.all.temp[!duplicated(df.all.temp[c("IDD")] ), ]
    
    # add it back
    df.sdadm <- merge(x=df.sdadm[,c("IDD", "sdadm")],y=df.all.temp.fields, by="IDD", all.x=TRUE)
    
    # Remove NAs from merge
    df.sdadm <- df.sdadm[!(is.na(df.sdadm$Station_ID)),]
    
    df.sdadm$Result <- df.sdadm$sdadm
    
    # only keep columns in df.all
    df.sdadm <- df.sdadm[,colnames(df.sdadm) %in% colnames(df.all)]
    
    df.sdadm$Analyte <- "Temperature"
    
    #trend_pass <- dplyr:filter(df.sdadm, 
    #                           Station_ID %in% qc.1.stn & Station_ID %in% qc.2.stn & Station_ID %in% qc.3.stn)
    
    # now remove temperature from df.all and replace with 7DADM values
    df.all <- df.all %>%
      filter(!Analyte == "Temperature") %>%
      rbind(df.sdadm)
    
    if(NROW(qc.3.pass) > 0) {
      qc.3.pass$Analyte <- "Temperature"
      df.all$month <- month(df.all$Sampled)
      qc.3.pass <- dplyr::rename(qc.3.pass, monTest = result)
      df.all <- merge(df.all, qc.3.pass[,c("Station_ID", "month", "monTest", "Analyte")], 
                      by=c("Station_ID", "Analyte", "month"), all.x = TRUE, all.y = FALSE)
    }
    
  }

  save(df.all, file=paste0(Rdata_dir,"/",df_all_clean_file))
  
}

```

```{r Create-other-dataframes}

if (any(c('pH', 'E. Coli', "Enterococcus", "Dissolved Oxygen", 'Total Suspended Solids', 'Total Phosphorus') %in% df.all$Analyte)) {
  seaken_other <- run_seaKen(filter(df.all, Analyte %in% c('pH', 
                                                           'E. Coli', 
                                                           "Enterococcus", 
                                                           "Dissolved Oxygen", 
                                                           'Total Suspended Solids', 
                                                           'Total Phosphorus')))
} else {seaken_other <- data.frame()}

if(NROW(dplyr::filter(df.all, Analyte == "Temperature" & monTest == "pass")) > 0) {
  seaken_temp <- run_seaKen(dplyr::filter(df.all, Analyte == "Temperature" & monTest == "pass"))
} else {seaken_temp <- data.frame()}

SeaKen <- rbind(seaken_other, seaken_temp)

status <- Stations_Status(df.all)
trend <- Stations_Trend(df.all)
stns_by_year <- Stations_by_Year(df.all)
stns <- All_stns_fit_Criteria(trend = trend, 
                             status = status,
                             df.all = df.all)

#print(stns)

df.stns <- df.all[df.all$Station_ID %in% unique(stns$Station_ID),]
stn_totals <- summarizeByStation(df.stns)
all.sp <- generateStnLyrToPlot(df.stns, stn_totals) #changed lat and long names

all_stn_sp <- all_stn_sp(df.all)
stn_nlcd_df <- landUseAnalysis(all.sp, cats, NLCD2011)

save(stns, file = paste0(Rdata_dir,"/", stns_file))
save(status, file = paste0(Rdata_dir,"/", status_file))
save(trend, file = paste0(Rdata_dir,"/", trend_file))

```

# Introduction

## Purpose

Area rules and plans have been adopted by the Oregon Department of Agriculture (ODA) for the `r input$select` agricultural water quality management area (`r OAR_LU[OAR_LU$AgArea %in% input$select,'OAR']`). Oregon statute and administrative rules require ODA to consult with the Department of Environmental Quality (DEQ) during the biennial review of Agricultural Water Quality Management Area Rules and Plans (ORS 568.930).  DEQ Total Maximum Daily Load (TMDL) and Nonpoint Source (NPS) program staff conduct these reviews based on ODA's biennial review schedule of their area rules and plans. ODA's Agriculture Water Quality Program is outcome based, explicitly describing prohibited conditions, similar to DEQ's TMDL and NPS programs which explicitly define water quality targets and goals.  The analysis of landscape conditions and water quality data is used for implementing these programs as well as identifying data gaps. 

This report presents data and analysis that will help DEQ fulfill its roles in the biennial review process described in the Memorandum of Agreement between ODA and DEQ. Water quality status and trends reports are created to inform discussions between DEQ Basin Coordinators and ODA Agriculture Water Quality Specialists prior to the Local Advisory Committee meeting. The discussions between DEQ and ODA prior to the LAC meeting could include: water quality and what's working and not working, source(s) and solutions, data needs and future monitoring to answer these questions. This report presents an analysis of water quality data readily accessible from public databases and available in sufficient quantity to indicate status and trends. Dependent on data availability, DEQ will use the available water quality data to answer the first three questions below. For the fourth bullet, the report is expected to inform DEQ Basin Coordinator analysis, interpretation, and discussion with ODA and the LAC about possible or potential sources:

*	What is the status of water quality? 
*	What is the trend in water quality? 
*	When applicable, are TMDL load allocations for total phosphorus and total suspended solids being met?
* Can water quality status and trends be attributed to a pollution source or sources?

DEQ basin coordinators review pertinent information including this report as part of ODA's biennial review. DEQ basin coordinators recommend changes and additional data and resources necessary to achieve water quality criterion and meet TMDL load allocations through ODA's survey. 

## Basin Contact


```{r basin-contact, results="asis"}

deq<- paste(BC_LU[BC_LU$AgArea %in% input$select, 'DEQ_bc_name'], BC_LU[BC_LU$AgArea %in% input$select, 'DEQ_bc_email'], sep = '; ')

oda<- paste(BC_LU[BC_LU$AgArea %in% input$select, 'ODA_agwqcoord_name'], BC_LU[BC_LU$AgArea %in% input$select, 'ODA_agwqcoord_number'], sep = '; ')

BC_table<-data.frame(input$select, deq, oda)
colnames(BC_table) <- c('AgWQ Management Area', 'DEQ Basin Coordinator', 'ODA AgWQ Specialist')

knitr::kable(BC_table, 
             format = "markdown", 
             padding = 2, digits = 1, caption = 
               tbls(name = "basinContact", caption =
                      "Oregon DEQ and ODA basin contacts**")
)

```

# Methods

## Data Sources

Analysts retrieved data from [DEQ](http://www.oregon.gov/deq/wq/Pages/WQdata.aspx) (LASAR and ELEMENT), EPA ([Storet](https://www.epa.gov/waterdata/water-quality-data-wqx)) USGS ([NWIS](https://qwwebservices.usgs.gov/), [Water Quality Portal](https://www.waterqualitydata.us/)) databases. Many other organizations provided data that were queried and evaluated for use in this report (see Appendix). Data collected between `r input$dates[1]` to `r input$dates[2]` were included in this report. Parameters included in the query were temperature, pH, dissolved oxygen, total suspended solids, total phosphorus, and bacteria.

Monitoring stations that had at least two years of recent data and/or at least 8 years of data fit the criteria to assess status and trends (see flow chart in full report). Stations that did not meet either of these criteria were not assessed for status or trends, but these stations were included in this report.

The data returned were evaluated for data quality. DEQ data included  `r unique(df.all[df.all$Database == 'Element' | df.all$Database == 'LASAR', 'Status'])` data that were rated under the [DEQ's Laboratory Quality Manual](http://www.oregon.gov/deq/FilterDocs/DEQ91LAB0006QMP.pdf) guidelines. EPA and USGS data were included unless result comments indicated problems with the data. Recent provisional data (after June 2014) from the USGS were included in this analysis. 

## Decision Criteria

Status and long-term water quality trends were compared to to water quality criteria or TMDL allocations. The decision criterion shown below was created for selecting stations that had greater than eight years of data and/or data to address water quality status. Monitoring data collected in tribal lands were not included in this analysis. Dominant upstream land use characteristics were calculated for stations, but were not used to decide what stations to include in this report.

```{r flowchart, fig.cap=figs(name="DecisionFlow", caption="Monitoring station decision criteria to ensure the stations contain sufficient data to represent status and trends for the waterbody**")}

knitr::include_graphics(path = "Figures/Agreview_flowchart_V5.png")

```

# Analysis

DEQ compared pH results from both grab and continuous sample data to the water quality criterion. The bacteria standard is based on the presence of E. coli compared to a single sample maximum and a geometric mean of five or more samples in a 90 day period. The temperature standard is based on the calculation of the seven day average of the daily maximum stream temperatures. When applicable, total suspended solids and total phosphorus were compared to the TMDL load allocation. If no allocation was present, total suspended solid and total phosphorus result values were plotted over time. Trends for pH, E. coli, total phosphorus, and total suspended solids were assessed using Seasonal Kendall Analysis, which removes the influence of season-to-season fluctuations .  The Seasonal Kendall Analysis also indicates the statistical significance and slope of the trend [Hirsch et al. 1982](https://profile.usgs.gov/myscience/upload_folder/ci2012Oct1508260828033Techniques%20of%20Trend%20Analysis%20for%20Monthly%20Water%20Quality%20Data.pdf). 

Dissolved oxygen (DO) was assessed by comparing the concentration to the water quality criterion. If the DO concentration exceeded the water quality criterion, but met the criteria for percent saturation at the same time, it was considered to be in compliance with the water quality criterion. These points were noted in the plots using a different color. Fish use and spawning maps  and the DO criteria flow chart  were used to determine the applicable temperature and DO standards for the spawning and non-spawning time periods. 

For temperature trend analysis, analysts used data only from stations with eight years of continuous hourly temperature data in each month during the query period. Data were not used if observations were missing for more than one day each month or if fewer than 22 hourly measurements were recorded during the day. These criteria resulted in no more than 10% missing data across each of the temporal periods of interest. Trends in the data were tested using a Mann Kendall test (Mann 1945). Trends were evaluated on the following metrics:

* Average Monthly 7-day average daily maximum
* Average Monthly daily degree hours > the applicable temperature standard. 

Trends are more detectable with the average monthly daily degree hours that exceed the applicable temperature standard because the metric incorporates both magnitude and duration of temperatures; the 7-day average daily maximum only incorporates the magnitude of exceedance. Fish use and spawning maps  were used to determine the applicable temperature standards for the spawning and non-spawning time periods. The results of this report includes graphs for stations with data that exceeded a water quality criterion more than once and/or showed a positive or negative trend. When insufficient data were available, that was noted in the graphs. 

# Results

`r length(unique(stn_to_use))` monitoring stations contained sufficient data to assess status and/or trends out of `r length(unique(df.all$Station_ID))` total monitoring stations within the `r agwqma` AgWQ Management Area 


Analyte         | Number of stations w/ sufficent data for status analysis | Number of stations w/ sufficent data for trend analysis
----------------|----------------------------------------------------- | ----------------------------------------------------
Bacteria        | `r nrow(unique(status[status$Analyte == "E. Coli", ]))` | `r nrow(unique(trend[trend$Analyte == "E. Coli", ]))`
Temperature     | `r nrow(unique(status[status$Analyte == "Temperature", ]))` | `r nrow(unique(trend[trend$Analyte == "Temperature", ]))`
Dissolved Oxygen| `r nrow(unique(status[status$Analyte == "Dissolved Oxygen", ]))` | `r nrow(unique(trend[trend$Analyte == "Dissolved Oxygen", ]))`
pH              | `r nrow(unique(status[status$Analyte == "pH", ]))` | `r nrow(unique(trend[trend$Analyte == "pH",]))`
TSS             | `r nrow(unique(status[status$Analyte == "Total Suspended Solids", ]))` | `r nrow(unique(trend[trend$Analyte == "Total Suspended Solids", ]))`
Total Phosphorus| `r nrow(unique(status[status$Analyte == "Total Phosphorus", ]))` | `r nrow(unique(trend[trend$Analyte == "Total Phosphorus", ]))`

## Station Locations
Within the `r input$select` AgWQ Management Area, `r length(unique(stns$Station_ID))` out of `r length(unique(df.all$Station_ID))` monitoring stations fit the criteria to assess water quality status and trends. The following maps show monitoring stations that fit the criteria within the watershed, all stations that were queried, land ownership, and landscape attributes. 

```{r stations-map-word, fig.cap=figs(name="stationsmap", caption="Monitoring station locations within the North Coast AgWQ Management Area**")}

knitr::include_graphics(path = paste0(project_dir,"/Figures/",station_map_file))

```

## Land Use

A land use analysis for catchments above all monitoring stations that fit the criteria to assess water quality status and/or trends was generated. Specifically, the Stream-Catchment ([StreamCat](https://www.epa.gov/national-aquatic-resource-surveys/streamcat)) dataset developed by EPA (based on the National Hydrography Dataset Plus Version 2 geospatial framework) was used to summarize the cumulative upstream catchment of each station for primary land use characteristics. An informative representation of land use and land cover (NLCD 2011) is shown in the station locations map below. 


```{r landuse-map-word, eval = word_output, fig.cap=figs(name="landusemap", caption="Land use and land cover within the North Coast AgWQ Management Area**")}

knitr::include_graphics(path = paste0(project_dir,"/Figures/",landuse_map_file))

```


```{r landuse-map-html, results= 'asis', eval = !(word_output)}

agarea_shp <- agwqma_shp[agwqma_shp$PlanName == input$select,]
agarea_shp <-spTransform(agarea_shp, CRS("+proj=longlat +datum=NAD83"))

map <- leaflet(agarea_shp) %>%
  addPolygons() %>%
  addTiles() %>%
  addMarkers(data = all.sp, 
             lng = all.sp@coords[,1], 
             lat = all.sp@coords[,2], 
             popup = paste("<style> div.leaflet-popup-content {width:auto !important;}</style>",
                           lapply(rownames(all.sp@data), 
                                  function(row) {
                                    htmlTable::htmlTable(all.sp@data[row,],
                                                         header = c('Stn_ID', 'Stn_Name',
                                                                    names(all.sp@data)[-c(1,2)]),
                                                         rnames = FALSE)
                                  })),
             group = 'Stations That Fit Criteria') %>%
  addMarkers(data = all_stn_sp, 
             lng = all_stn_sp@coords[,1], 
             lat = all_stn_sp@coords[,2], 
             popup = paste("<style> div.leaflet-popup-content {width:auto !important;}</style>",
                           lapply(rownames(all_stn_sp@data),
                                  function(row) {
                                    htmlTable::htmlTable(all_stn_sp@data[row,],
                                                         header = c('Stn_ID', 'Stn_Name',
                                                                    names(all_stn_sp@data)[-c(1,2)]),
                                                         rnames = FALSE)
                                  })),
             group = 'All Stations Queried') %>%
  hideGroup('All Stations Queried') %>%
  addWMSTiles('https://www.mrlc.gov/arcgis/services/LandCover/USGS_EROS_LandCover_NLCD/MapServer/WMSServer?',
              group = "Land Use (NLCD 2011)",
              layers = '33',
              options = WMSTileOptions(format = 'image/png',
                                       version = '1.3.0',
                                       transparent = TRUE)) %>% 
  addWMSTiles(GetURL("USGSTopo"), 
              attribution = paste0("<a href='https://www.usgs.gov/'>",
                                   "U.S. Geological Survey</a> | ",
                                   "<ahref='https://www.usgs.gov/laws/policies_notices.html'>",
                                   "Policies</a>"),
              group = "USGS Topo", layers = "0") %>%
  addWMSTiles(GetURL("USGSHydroCached"), 
              group = "Hydrography", 
              options = WMSTileOptions(format = "image/png", 
                                       transparent = TRUE),
              layers = "0") %>%
  hideGroup("Hydrography") %>%
  addProviderTiles(providers$Esri.NatGeoWorldMap) %>%
  addLayersControl(baseGroups = c('Land Use (NLCD 2011)', 'USGS Topo', 'ESRI NatGEO World Map'),
                   overlayGroups = c('Stations That Fit Criteria', 'All Stations Queried', 'Hydrography'),
                   options = layersControlOptions(collapsed = FALSE))
map

```


Summary table of watershed land use by station, only stations which have at least 8 years of yearly data (between 2000 and 2017) and/or are used to evaluate last known status. Source: 2011 NAIP


```{r landuse-table, results='asis'}

stn_to_use<-c(unique(stns$Station_ID))

landuse<-stn_nlcd_df%>%
  filter(Station_ID %in% stn_to_use) %>%
  arrange(desc(PerAgWs))
colnames(landuse) <- c("Station ID", "Station Description", "Year", "Watershed Area (km^2^)",
                       "% Urban", "% Forest", "% Ag", "% Range", "% Other")
landuse <-landuse[, - 3]

save(landuse, file=paste0(Rdata_dir,"/", landuse_file))

knitr::kable(landuse, digits = 0, 
             format = "markdown", 
             padding = 2, caption = tbls(name = "landUse", caption = "Summary table of watershed land use by station, only stations which have at least 8 years of yearly data (between 2000 and 2017) and/or are used to evaluate last known status.**"))

```

## Water Quality Limited Stream Segments
Summary of Oregon's 2012 Integrated Report Assessment database and 303(d) list for parameters included in this report. Table based on the 2012 Integrated Report Listings by the EPA. Note that pH exceedances are values higher or lower than the given range.

```{r wq-limited}

wq_lim_whole <- extract_303d(df.all, wq_limited, input$select)
wq_lim_whole <- wq_lim_whole[,c('STREAM_LAK', 'LLID_STREA', 
                                'MILES', 'POLLUTANT', 'SEASON', 
                                'ASSESSME_1', 'CRITERIA', 
                                'LISTING_ST', 'TMDL_INFO')]
wq_lim_whole <- plyr::rename(wq_lim_whole, 
                             c('STREAM_LAK' = 'Waterbody',
                               'LLID_STREA' = 'LLID',
                               'ASSESSME_1' = 'Year Assessed',
                               'LISTING_ST' = 'Listing Status'))

wq_limited_df <- wq_lim_whole[, c('Waterbody', 'MILES', 'POLLUTANT', 'SEASON', 'Year Assessed', 'CRITERIA', 'Listing Status')]

names(wq_limited_df) <- c('Waterbody', 'Miles', 'Pollutant', 'Season', 'Year Assessed', 'Criteria', 'Listing Status')

wq_limited_df <- wq_limited_df %>% arrange(desc(Waterbody))

wq_limited_df$`Listing Status` <- revalue(wq_limited_df$`Listing Status`, 
                                          c("Cat 4A: Water quality limited, TMDL approved" = "Cat 4A",
                                            "Cat 5: Water quality limited, 303(d) list, TMDL needed" = "Cat 5",
                                            "TMDL approved" = "Cat 4A",
                                            "303(d)" = "Cat 5"))

knitr::kable(wq_limited_df, padding = 2, caption = tbls(name = "wqLimited", caption = "Summary of Integrated Report listings for parameters included in this report. Table based on the approved (and partially disapproved) 2012 Integrated Report Listings by the EPA**"))

```

## Seasonal Kendall Trend Analysis

For all monitoring stations with sufficient data (8 years or more), trending was performed using Seasonal kendall trend analysis. Results are summarized in the table below. (If no table is visible, there were no monitoring station that contained sufficient data to assess trends.)


<!-- Output for the Seasonal kendall analysis, which was performed on data that had at least 8 years of data between 2000 and 2017. Only stations used in this analysis are included in this table. The values in the N column represent the number of results for each analyte at each monitoring station and includes duplicate values; the slope refers to the slope of the trend line; the p-value represents the statistical significance of the trend (p<0.8 is significant and is defined in the 'significant' column); median represents the median value of all assessed results for each station at each monitoring station.   -->

```{r Seasonal-Kendall}

SK <- SeaKen %>% filter(Station_ID %in% unique(stns$Station_ID)) %>% 
  filter(signif !=  "Need at least 8 years") %>% 
  filter(analyte != 'Dissolved oxygen saturation')

if(nrow(SK) > 0) {
  
  SK <- SK[,c(1, 2, 3, 4, 5, 8, 9)]
  SK <- SK[with(SK, order(analyte, Station_ID)),]
  
  SK$slope <- as.numeric(SK$slope)
  SK$pvalue <- as.numeric(SK$pvalue)

  colnames(SK) <- c("Station ID", "Analyte", "Slope", "p value", "Median", "N", "Significance Result")
  
  knitr::kable(SK, padding = 2, format.args = list(scientific = TRUE), caption = tbls(name = "seakenTable", caption = "Output for the Seasonal Kendall analysis, which was performed on data that had at least 8 years of data between 2000 and 2017. Only stations used in this analysis are included in this table. The values in the N column represent the number of results for each analyte at each monitoring station and includes duplicate values; the slope refers to the slope of the trend line; the p-value represents the statistical significance of the trend (p<0.8 is significant and is defined in the 'significant' column); median represents the median value of all assessed results for each station at each monitoring station.**"))
}

```

## E.coli

```{r Ecoli, fig.height=6, fig.width=6, results='asis'}

exc <- NULL
ecoli_stns <- NULL

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  ecoli_trend <- trend %>%
    dplyr::filter(Analyte == "E. Coli")
  ecoli_trend <- c(unique(ecoli_trend$Station_ID))
}

ecoli_stat <- status %>%
  dplyr::filter(Analyte == "E. Coli")
ecoli_stat <- c(unique(ecoli_stat$Station_ID))

ecoli_stns <- unique(append(ecoli_trend, ecoli_stat))

if(length(ecoli_stns) > 0) {
  
  ecoli_all <- df.all[df.all$Analyte == 'E. Coli',]
  ecoli <- df.all[df.all$Analyte == 'E. Coli',]
  
  ecoli_list<- list()
  exc_list<- list()
  
  results_seaken <-SeaKen %>% filter(analyte == 'E. Coli')
  
  for(j in 1: length(ecoli_stns)) {
    new_data <- ecoli[ecoli$Station_ID == ecoli_stns[j],]
    tmp_df <- new_data
    tmp_df$day <- substr(tmp_df$Sampled, 1, 10)
    tmp_df$code <- paste(tmp_df$Station_ID, tmp_df$Analyte, tmp_df$day)
    sub <- with(tmp_df, resolveMRLs(code, Detect, Result))
    tmp_df_MRL <- tmp_df[sub,]
    tmp_df <- remove.dups(tmp_df_MRL, max)
    
    ecoli_evaluate <- EvaluateEColiWQS(tmp_df)
    ecoli_eval <- attr(ecoli_evaluate, 'ex_df')
    ecoli_list[[j]] <- ecoli_evaluate
    exc_list[[j]] <- ecoli_eval
    
    trend_logic <- ifelse(grepl("Not Significant", 
                                results_seaken[results_seaken$Station_ID == ecoli_stns[j],'signif']),
                          FALSE,
                          ifelse(grepl("Need at least 8 years", 
                                       results_seaken[results_seaken$Station_ID == ecoli_stns[j],'signif']),
                                 FALSE, 
                                 TRUE))
    
    b <- plot.bacteria(new_data=new_data,
                       sea_ken_table=results_seaken ,
                       plot_trend = trend_logic,
                       plot_log = FALSE,
                       parm = unique(new_data$Analyte))
    
    print(b)
    cat(figs(name = paste0('E_', ecoli_stns[j]), caption = paste0('Station: ', ecoli_stns[j], ' _E. Coli_ water quality status and/or trends**')))
    
  }
  
  ecoli <- rbind.fill(ecoli_list[])
  exc <- rbind.fill(exc_list[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100

  knitr::kable(exc, padding = 2, digits = 1,
               caption = tbls(name = "ecoliExcTable", 
                              caption = "E. Coli status and trends, if sufficient data exists to calculate the geometric mean, it is included in the table.**"))
}  else {
  print("No monitoring stations have data to assess status and/or trend of E. Coli") 
} 

```

## Enterococcus 

```{r Enterococcus, fig.height=6, fig.width=6, results='asis'}

exc <- NULL
ent_stns <- NULL

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  ent_trend <- trend %>%
    dplyr::filter(Analyte == "Enterococcus")
  ent_trend <- c(unique(ent_trend$Station_ID))
}

ent_stat <- status %>%
  dplyr::filter(Analyte == "Enterococcus")
ent_stat <- c(unique(ent_stat$Station_ID))

ent_stns <- unique(append(ent_trend, ent_stat))

if(length(ent_stns) > 0) {
  
  ent_all <- df.all[df.all$Analyte == 'Enterococcus',]
  ent <- df.all[df.all$Analyte == 'Enterococcus',]
  
  ent_list<- list()
  exc_list<- list()
  
  for(j in 1: length(ent_stns)) {
    new_data <- ent[ent$Station_ID == ent_stns[j],]
    tmp_df <- new_data
    tmp_df$day <- substr(tmp_df$Sampled, 1, 10)
    tmp_df$code <- paste(tmp_df$Station_ID, tmp_df$Analyte, tmp_df$day)
    sub <- with(tmp_df, resolveMRLs(code, Detect, Result))
    tmp_df_MRL <- tmp_df[sub,]
    tmp_df <- remove.dups(tmp_df_MRL, max)
    
    ent_evaluate <- EvaluateEnteroWQS(tmp_df)
    ent_eval <- attr(ent_evaluate, 'ex_df')
    ent_list[[j]] <- ent_evaluate
    exc_list[[j]] <- ent_eval
  }
  
  ent <-rbind.fill(ent_list[])
  exc <-rbind.fill(exc_list[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  results_seaken <-SeaKen %>% filter(analyte == 'Enterococcus')
  
  ent_plots <-list()
  
  for (i in 1:length(ent_stns)) {
    mydata_sub <- ent_all[ent_all$Station_ID == ent_stns[i],]
    
    trend_logic <- ifelse(grepl("Not Significant", results_seaken[results_seaken$Station_ID == ent_stns[i],'signif']), FALSE,
                          ifelse(grepl("Need at least 8 years", results_seaken[results_seaken$Station_ID == ent_stns[i],'signif']), FALSE, TRUE))
    
    
    b <- plot.bacteria(new_data=mydata_sub,
                       sea_ken_table=results_seaken ,
                       plot_trend = trend_logic,
                       plot_log = FALSE,
                       parm = unique(mydata_sub$Analyte))
    
    ent_plots[[i]] <- b

    print(ent_plots[[i]])
    
    cat(figs(name = paste0('Entero_', ent_stns[i]),
             caption = paste0('Station: ', ent_stns[i], ' _Enterococcus_ water quality status and trends**')))
  }
  
  knitr::kable(exc, padding = 2, digits = 1,
               caption = tbls(name = "enterExcTable", 
                              caption = "Enterococcus status and trends, if sufficient data exists to calculate the geometric mean, it is included in the table.**"))
}  else {
  print("No monitoring stations have data to assess status and/or trend of Enterococcus") 
} 

```

## Total Phosphorus

```{r Total-Phosphorus, results = 'asis', fig.width = 6, fig.height = 6}

exc <- NULL
tp_stn <- NULL

if(!(trend == "No Stations Meet Trend Criteria")) {
  tp_stn<-trend %>%
    dplyr::filter(Analyte == "Total Phosphorus")
  tp_stn<-c(as.character(unique(tp_stn$Station_ID)))
}

tp_stat<-status %>%
  dplyr::filter(Analyte == "Total Phosphorus")
tp_stat <- c(as.character(unique(tp_stat$Station_ID)))

if(!is.null(tp_stn)){
  tp_stn <- unique(append(tp_stn, tp_stat))
}else{
  tp_stn <- tp_stat
}

if(length(tp_stn) > 0) {
  
  TP_all <- df.all[df.all$Analyte == 'Total Phosphorus',]
  TP <- df.all[df.all$Analyte == 'Total Phosphorus',]
  
  # if (input$select == 'Tualatin River Subbasin') {
  #   
  #   TP_alloc <- evaluate_tp_alloc(TP_all, tp_stn) ####TMDL load allocation
  #   #trib <- tp_list[[1]]
  #   #summer <- tp_list[[2]]
  # }
  #} else {
    
    TP_list<- list()
    TP_exclist<- list()
    for(j in 1: length(tp_stn)) {
      new_data <- TP[TP$Station_ID == tp_stn[j],]
      
      tmp_df <- new_data
      tmp_df$day <- substr(tmp_df$Sampled, 1, 10)
      tmp_df$code <- paste(tmp_df$Station_ID, tmp_df$Analyte, tmp_df$day)
      sub <- with(tmp_df, resolveMRLs(code, Detect, Result))
      tmp_df_MRL <- tmp_df[sub,]
      tmp_df <- remove.dups(tmp_df_MRL, max)
      
      if(input$select == 'Powder-Brownlee'| input$select == 'Burnt River') { #Snake River Hells Canyon TMDL allocation 2004
        TP_evaluate <- EvaluateTPWQS(tmp_df, 
                                     selectWQSTP = 0.07)
      } else {
        
        TP_evaluate <- EvaluateTPWQS(tmp_df, 
                                     selectWQSTP = 0)
      }
      
      TP_eval <- attr(TP_evaluate, 'ex_df')
      TP_list[[j]] <- TP_evaluate
      TP_exclist[[j]] <- TP_eval
    }
    
    TP<-rbind.fill(TP_list[])
    exc<-rbind.fill(TP_exclist[])
    exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
    
}

results_seaken<-SeaKen %>% filter(analyte == 'Total Phosphorus')

tp_plots<-list()
for (i in 1:length(tp_stn)) {
  mydata_sub <- TP_all[TP_all$Station_ID == tp_stn[i],]
  
  trend_logic<-ifelse(grepl("Not Significant", results_seaken[results_seaken$Station_ID == tp_stn[i],'signif']), FALSE,
                      ifelse(grepl("Need at least 8 years", results_seaken[results_seaken$Station_ID == tp_stn[i],'signif']), FALSE, TRUE))
  
  if(input$select == 'Powder-Brownlee' | input$select == 'Burnt River') {
    b <- plot.TP(new_data=mydata_sub,
                 df.all = df.all,
                 sea_ken_table=results_seaken ,
                 plot_trend = trend_logic,
                 selectWQSTP = 0.07,
                 parm = unique(mydata_sub$Analyte))
    # } else if (input$select == 'Tualatin River Subbasin') {
    #   new_data <- TP_alloc[TP_alloc$Station_ID == unique(TP_alloc$Station_ID)[i],]
    #   b <- tp_alloc_plot(TP_alloc = new_data,
    #                      sea_ken_table = results_seaken,
    #                      plot_trend = trend_logic)
  } else {
    b <- plot.TP(new_data=mydata_sub,
                 df.all = df.all,
                 sea_ken_table=results_seaken ,
                 plot_trend = trend_logic,
                 selectWQSTP = 0,
                 parm = unique(mydata_sub$Analyte))
  }
  
  #ggsave(plot = b, filename = paste('TP_plots', unique(new_data$Station_ID), '.png'), width = 6, height = 6)
  
  tp_plots[[i]]<-b
  
  print(tp_plots[[i]])
  cat(figs(name = paste0('TP_', tp_stn[i]), caption = paste0('Station: ', tp_stn[i], ' _Total Phosphorus_ water quality status and trends**')))
} 

colnames(exc) <- c("Station ID","Station Description", "Min Date", "Max Date", "Obs", "Exceedances", "% Exceedance")
exc <- exc[,c(1:5)]
knitr::kable(exc,padding = 2, digits = 1, caption = tbls(name = "tpExcTable", caption = "Total Phosphorus status and trends**"))

# }else {
#   print("No monitoring stations have sufficent data to assess status and/or trend of total phosphorus")
# }
#} 

tp_exc <- exc
#}

```

<!-- Total Phosphorus TMDL Loading Capacity Evaluation -->
<!-- The 2001/2012 Tualatin River Subbasin TMDL loading capacity values were applied to total phosphorus results within the Tualatin River Subbasin. The loading capacity (or TMDL target) defines the total amount of pollutant that a waterbody can receive and still meet water quality standards. This definition includes both natural and human sources. The loading capacity is defined as a summer (June - September) median. Boxplots are presented to show the summer distribution of total phosphorus as well as the median and how it compares to the loading capacity target ([Tualatin Total Maximum Daily Load (TMDL) and Water Quality Management Plan (WQMP)](http://www.oregon.gov/deq/FilterDocs/tmdlwqmp.pdf]) . -->

<!-- ```{r TP loading capacity evaluation, echo = FALSE, message = FALSE, warning=FALSE, error = TRUE, fig.width = 8, fig.height = 8, fig.cap = "Median total phosphorus results relative to the applicable loading capacity (identified in the Tualatin River TMDL 2001/2012). The loading capacity is shown as the dark green dashed line. The median value of results for each summer is marked as a red dot and labeled numerically above. If the median is above the load capacity, it is in exceedance of the TMDL allotted loading capacity." } -->
<!-- source('T:/AgWQM/DataAnalysis/StatusAndTrendsRMarkdown/functions/TualatinR_Allocations.R') -->

<!-- plots<-list() -->
<!-- for (i in 1:length(tp_stn)) { -->
<!--   mydata_sub <- TP_all[TP_all$Station_ID == tp_stn[i],] -->

<!--   b <- tp_alloc_boxplot(TP_alloc = mydata_sub) -->

<!--   plots[[i]]<-b -->

<!--   print(plots[[i]]) -->

<!-- }  -->
<!-- ``` -->

## Total Suspended Solids

```{r TSS, results = 'asis', fig.width = 6, fig.height = 6}

exc <- NULL
tss_stn <- NULL


if(!(trend == "No Stations Meet Trend Criteria")) {
  tss_stn<-trend %>%
    dplyr::filter(Analyte == "Total Suspended Solids")
  tss_stn<-c(unique(tss_stn$Station_ID))
}

  tss_stat<-status %>%
    dplyr::filter(Analyte == "Total Suspended Solids")
  tss_stat <- c(unique(tss_stat$Station_ID))
  
  if (!is.null(tss_stn)) {
    tss_stn <- (unique(append(tss_stn, tss_stat)))
  }else{
    tss_stn <- tss_stat
  }
  if(length(tss_stn) > 0){
    
  TSS_all <- df.all[df.all$Analyte == 'Total Suspended Solids',]
  TSS <- df.all[df.all$Analyte == 'Total Suspended Solids',]
  
  TSS_list<- list()
  TSS_exclist<- list()
  for(j in 1: length(tss_stn)) {
    new_data <- TSS[TSS$Station_ID == tss_stn[j],]
    
    tmp_df <- new_data
      tmp_df$day <- substr(tmp_df$Sampled, 1, 10)
      tmp_df$code <- paste(tmp_df$Station_ID, tmp_df$Analyte, tmp_df$day)
      sub <- with(tmp_df, resolveMRLs(code, Detect, Result))
      tmp_df_MRL <- tmp_df[sub,]
      tmp_df <- remove.dups(tmp_df_MRL, max)
    
    if (input$select == 'Powder-Brownlee') {
    TSS_evaluate <- EvaluateTSSWQS(tmp_df, 
                                   selectWQSTSS = 50)
    } else {
      TSS_evaluate <- EvaluateTSSWQS(tmp_df, 
                                   selectWQSTSS = 0)
    }
    TSS_eval <- attr(TSS_evaluate, 'ex_df')
    TSS_list[[j]] <- TSS_evaluate
    TSS_exclist[[j]] <- TSS_eval
  }
  
  TSS<-rbind.fill(TSS_list[])
  exc<-rbind.fill(TSS_exclist[])
  exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  results_seaken<-SeaKen %>% filter(analyte == 'Total Suspended Solids')
  
  tss_plots<-list()
  for (i in 1:length(tss_stn)) {
    mydata_sub <- TSS_all[TSS_all$Station_ID == tss_stn[i],]
    
    
    trend_logic<-ifelse(grepl("Not Significant", results_seaken[results_seaken$Station_ID == tss_stn[i],'signif']), FALSE,
                        ifelse(grepl("Need at least 8 years", results_seaken[results_seaken$Station_ID == tss_stn[i],'signif']), FALSE, TRUE))
    
    if (input$select == 'Powder-Brownlee') {
    b <- plot.TSS(new_data=mydata_sub,
                  df.all = df.all,
                  sea_ken_table=results_seaken ,
                  plot_trend = trend_logic,
                  selectWQSTSS = 50,
                  parm = unique(mydata_sub$Analyte))
    } else {
      b <- plot.TSS(new_data=mydata_sub,
                  df.all = df.all,
                  sea_ken_table=results_seaken ,
                  plot_trend = trend_logic,
                  selectWQSTSS = 0,
                  parm = unique(mydata_sub$Analyte))
    }
    
    tss_plots[[i]]<-b
    
    print(tss_plots[[i]])
    cat(figs(name = paste0('TSS_', tss_stn[i]), caption = paste0('Station: ', tss_stn[i], ' _Total Suspended Solids_ water quality status and trends**')))
  } 
colnames(exc) <- c("Station ID","Station Description", "Min Date", "Max Date", "Obs", "Exceedances", "% Exceedance")
exc <- exc[,c(1:5)]
  knitr::kable(exc, padding = 2, digits = 1, caption = tbls(name = "tssExcTable", caption = "Total Suspended Solids status and trends**"))

# }else {
#   "No monitoring stations have sufficent data to assess status and/or trend of total suspended solids"
# }
}
tss_exc <- exc

```

## pH

```{r pH, results = 'asis', fig.width = 6, fig.height = 6}

exc <- NULL
pH_stn_table <- NULL

if(any(!(trend == "No Stations Meet Trend Criteria"))) {
  pH_stn<-trend %>%
    dplyr::filter(Analyte == "pH")
  pH_stn_table<-c(unique(pH_stn$Station_ID))
}
  
  p_stat<-status %>%
    dplyr::filter(Analyte == "pH")
  p_stat <- c(unique(p_stat$Station_ID))
  
  if(!is.null(pH_stn_table)){
  pH_stn_table <- unique(append(pH_stn_table, p_stat))
  }else{
    pH_stn_table <- p_stat
  }
  if(length(pH_stn_table) > 0) {
    
  pH_all <- df.all[df.all$Analyte == 'pH',]
  pH <- df.all[df.all$Analyte == 'pH',]
  
  in_bentable<-(Ben_use_LU[Ben_use_LU$Station_ID %in% pH_stn_table, 'pH_benuse'])
  
  dta <- merge(pH, Ben_use_LU, by.x = "Station_ID", by.y = "Station_ID")
  pH_stn <- dta %>% filter(!is.na(pH_benuse))
  pH_stn <- c(unique(pH_stn$Station_ID))
  
  ph_exc <- NULL
  
  if(any(!is.na(in_bentable))) {
    
    pH_list<- list()
    pH_exclist<- list()
    for(j in 1: length(pH_stn)) {
      
      new_data <- pH[pH$Station_ID == pH_stn[j],]
      
      
      tmp_df <- new_data
      tmp_df$day <- substr(tmp_df$Sampled, 1, 10)
      tmp_df$code <- paste(tmp_df$Station_ID, tmp_df$Analyte, tmp_df$day)
      sub <- with(tmp_df, resolveMRLs(code, Detect, Result))
      tmp_df_MRL <- tmp_df[sub,]
      tmp_df <- remove.dups(tmp_df_MRL, max)
      
      pH_evaluate <- EvaluatepHWQS(new_data = tmp_df)
      
      pH_evaluate$Year <- as.POSIXct(strptime(pH_evaluate$Sampled, format = "%Y"))
      
      pH_eval <- ddply(pH_evaluate, .(Station_ID, Station_Description), #, Month), 
                       summarize, min_date = min(Year), 
                       max_date = max(Year),
                       Obs = length(exceed), 
                       Exceedances = sum(exceed)) 
      
      # pH_eval <- attr(pH_evaluate, 'ex_df')
      pH_list[[j]] <- pH_evaluate
      pH_exclist[[j]] <- pH_eval
    }
    
    pH<-rbind.fill(pH_list[])
    ph_exc<-rbind.fill(pH_exclist[])
    ph_exc$perc_exc <- (ph_exc$Exceedances / ph_exc$Obs) * 100
    colnames(ph_exc) <- c("Station ID", "Station Description", "Min Date", "Max Date", "# Obs", "# Exceed", "% Exceed")
    
  }
  #exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
  
  results_seaken<-SeaKen %>% filter(analyte == 'pH')
  
  if(length(pH_stn) > 0) {
    
    pH_plots<-list()
    for (i in 1:length(pH_stn)) {
      mydata_sub <- pH_all[pH_all$Station_ID == pH_stn[i],]
      
      
      trend_logic<-ifelse(grepl("Not Significant", results_seaken[results_seaken$Station_ID == pH_stn[i],'signif']), FALSE,
                          ifelse(grepl("Need at least 8 years", results_seaken[results_seaken$Station_ID == pH_stn[i],'signif']), FALSE, TRUE))
      
      ph_crit_min <- as.numeric(Ben_use_LU[Ben_use_LU$Station_ID == pH_stn[j], 'pH_low'])
      ph_crit_max <- as.numeric(Ben_use_LU[Ben_use_LU$Station_ID == pH_stn[j], 'pH_high'])
      crit_selected <- Ben_use_LU[Ben_use_LU$Station_ID == pH_stn[j], 'pH_benuse']
      plan_area <- Ben_use_LU[Ben_use_LU$Station_ID == pH_stn[j], 'AgArea']
      
      ########### continuous stations that should not have trend lines
      contstns <- c('USGS-14207200', 'USGS-14202980', 'USGS-423026123063401', "USGS-453040123065201")
      if(pH_stn[i] %in% contstns) {
        trend_logic <- FALSE
      }
      ###########
      
      b <- plot.ph(new_data = mydata_sub, 
                   sea_ken_table=SeaKen,
                   analyte_column = 'Analyte',
                   result_column = 'Result',
                   station_id_column = 'Station_ID',
                   station_desc_column = 'Station_Description',
                   datetime_column = 'Sampled', 
                   datetime_format = '%Y-%m-%d %H:%M:%S', 
                   plot_trend = trend_logic, 
                   ph_crit_min = ph_crit_min, 
                   ph_crit_max = ph_crit_max)
      
      
      pH_plots[[i]]<-b
      
      print(pH_plots[[i]])
      
      cat(figs(name = paste0('pH_', pH_stn[i]), caption = paste0('Station: ', pH_stn[i], ' _pH_ water quality status and trends**')))
      
    } 
    
  }
  pH_table <- as.data.frame(pH_stn_table)
  if(length(pH_stn > 0)){
    pH_table <- pH_table %>% filter(!(pH_stn_table %in% pH_stn))
  }
  colnames(pH_table) <- c("Station ID")
  
  if(nrow(pH_table)> 0) {
    print("In order to assess against water quality standard, need to add pH beneficial uses to stations.csv for stations:")
    print(pH_table)
  }
  
  if(!is.null(ph_exc)) {
    knitr::kable(ph_exc, padding = 2, digits = 1, caption = tbls(name = "phExcTable", caption = "pH status and trends**"))
  }
  # } else {
  #   print("No monitoring stations have sufficient data to assess pH")
  # }
}

```

## Temperature

```{r Temperature, results = 'asis', fig.width = 6, fig.height = 6}

if(any(!(trend == "No Stations Meet Trend Criteria"))) {

  temp_stn <- unique(filter(SeaKen, analyte == "Temperature")$Station_ID)
  
  t_stat <- unique(filter(status, Analyte == "Temperature")$Station_ID)
  
  temp_stn <- unique(append(temp_stn, t_stat))
  temp_stn_table <- temp_stn #all stations that meet the criteria for status or trend
  
  if(length(temp_stn) > 0) {
    
    sdadm <- df.all[df.all$Analyte == 'Temperature' & df.all$Station_ID %in% temp_stn_table,]
    
    #(Ben_use_LU[Ben_use_LU$Station_ID %in% pH_stn_table, 'pH_benuse'])
    in_bentable<-as.character(Ben_use_LU[Ben_use_LU$Station_ID %in% temp_stn_table, 'Temp_Benuse'])
    
    dta <- merge(sdadm, Ben_use_LU, by.x = "Station_ID", by.y = "Station_ID")
    temp_stn <- dta %>% filter(!is.na(Temp_Benuse))
    temp_stn <- unique(temp_stn$Station_ID) #All stations with beneficial uses attached
    
    temp <-NULL
    exc <-NULL
    
    temp_list<- list()
    temp_exclist<- list()
    
    ##if in_bentable is character empty (the stations do not exist in LU table)
    if(length(in_bentable) > 0) {
      
      if(any(!is.na(in_bentable))) {
        #temp <- df.all[df.all$Analyte == 'Temperature',]
        for(j in 1: length(temp_stn)) {
          
          new_data <- sdadm[sdadm$Station_ID == temp_stn[j], c("Station_ID", 
                                                               "Station_Description", 
                                                               "Sampled", "Result")]
          new_data$date <- as.Date(new_data$Sampled)
          #new_data <- na.omit(new_data)
          
          if(nrow(new_data) > 1) {
            
            Temp_Benuse <- as.character((Ben_use_LU[Ben_use_LU$Station_ID == temp_stn[j], 'Temp_Benuse']))
            spwn_time <- as.character(Ben_use_LU[Ben_use_LU$Station_ID == temp_stn[j], 'spwn_time'])
            
            temp_evaluate <- EvaluateTempWQS(sdadm_df = new_data,
                                             selectUse = Temp_Benuse[1],
                                             selectSpawning = spwn_time[1],
                                             station_column_name = 'Station_ID')
            
            temp_eval <- attr(temp_evaluate, 'result_summary')
            temp_list[[j]] <- temp_evaluate
            temp_exclist[[j]] <- temp_eval
            
          } else {
            
            temp_list[[j]] <- NULL
            temp_exclist[[j]] <- NULL
          }
        }
      }
      
      temp<-rbind.fill(temp_list[])
      exc<-rbind.fill(temp_exclist[])
      
      if(length(temp_stn) > 0 & length(sdadm) > 1) {
        temp_plots<-list()
        for (i in 1:length(temp_stn)) {
          
          #look up what to do if there is not enough temp data
          
          new_data <- sdadm[sdadm$Station_ID == temp_stn[i], c("Station_ID", 
                                                               "Station_Description", 
                                                               "Sampled", "Result")]
          new_data$date <- as.Date(new_data$Sampled)
          
          if(nrow(new_data) > 1) {
            
            if(temp_stn[i] %in% SeaKen[SeaKen$analyte == "Temperature", "Station_ID"]){
              trend_logic <- TRUE
            } else {trend_logic <- FALSE}
            
            Temp_Benuse <- as.character(Ben_use_LU[Ben_use_LU$Station_ID == temp_stn[i], 'Temp_Benuse'])
            spwn_time <- as.character(Ben_use_LU[Ben_use_LU$Station_ID == temp_stn[i], 'spwn_time'])
            
            temp_evaluate <- EvaluateTempWQS(sdadm_df = new_data,
                                             selectUse = Temp_Benuse[1],
                                             selectSpawning = spwn_time[1],
                                             station_column_name = 'Station_ID')
            
            
            b <- plot.Temperature(new_data = temp_evaluate,
                                  all_data = df.all,
                                  sea_ken_table = SeaKen,
                                  selectUse = Temp_Benuse[1],
                                  selectSpawning = spwn_time[1],
                                  station_id_column = 'Station_ID',
                                  station_desc_column = 'Station_Description',
                                  datetime_column = 'date',
                                  datetime_format = '%Y-%m-%d',
                                  plot_trend = trend_logic)
            
            
            temp_plots[[i]]<-b
            
            print(temp_plots[[i]])
            cat(figs(name = paste0('temp_', temp_stn[i]), caption = paste0('Station: ', temp_stn[i], ' _Temperature_ water quality status and trends**')))
            
          } else {
            print(paste("insufficient data to calculate sdadm at station:", temp_stn[i]))
          }
        }
      } else {
        print("insufficient data to calculate sdadm")
      }
      
      temp_table <- as.data.frame(temp_stn_table)
      #want to filter temp stations that do not have ben uses attached
      if(length(temp_stn) > 0){
        ttable <- temp_table %>% dplyr::filter(!(temp_stn_table %in% temp_stn))
      }
      
      colnames(ttable) <- c("Station ID")
      if (nrow(ttable) > 0) {
        print("In order to assess against water quality standard, need to add temperature beneficial uses and spawning time periods to stations.csv for stations:")
        print(ttable)
        
      }
      
      if(!is.null(exc)){ #prints exceedance table, if temperature stns exist 
        #fix column names
        knitr::kable(exc, padding = 2, digits = 1, caption = tbls(name = "tempExcTable", caption = "Temperature status and trends**"))
      }
      
    }
  }
} else {
  temp <- NULL
}
temp_exc <- exc

```

## Dissolved Oxygen

```{r Dissolved-Oxygen, results = 'asis', fig.width = 6, fig.height = 6}

exc <- NULL
DO_stn <- NULL
DO_stn_table <- NULL

if(any(trend != "No Stations Meet Trend Criteria")) {
  DO_stn<-trend %>%
    dplyr::filter(Analyte == "Dissolved Oxygen")
  DO_stn_table<-c(unique(DO_stn$Station_ID))
  DO_stn <- c(unique(DO_stn$Station_ID))
}
  
  DO_stat<-status %>%
    dplyr::filter(Analyte == "Dissolved Oxygen")
  DO_stat <- c(unique(DO_stat$Station_ID))
  
  
  if(!is.null(DO_stn)) {
  DO_stn <- unique(append(DO_stn, DO_stat))
  }else{
    DO_stn <- DO_stat
  }
  
  if(length(DO_stn) > 0) {
    
    DO_all <- df.all[df.all$Analyte == 'Dissolved Oxygen',]
    DO <- df.all[df.all$Analyte == 'Dissolved Oxygen',]
    
    #(Ben_use_LU[Ben_use_LU$Station_ID %in% pH_stn_table, 'pH_benuse'])
    in_bentable<-(Ben_use_LU[Ben_use_LU$Station_ID %in% DO_stn, 'DO_use'])
    
    dta <- merge(DO, Ben_use_LU, by.x = "Station_ID", by.y = "Station_ID")
    DO_stn <- dta %>% filter(!is.na(DO_use))
    DO_stn <- c(unique(DO_stn$Station_ID))
    
    #DO<-NULL
    #exc<-NULL
    DO_list<- list()
    DO_exclist<- list()
    if(any(!is.na(in_bentable))) {
      
      #DO <- df.all[df.all$Analyte == 'Dissolved Oxygen',]
      for(j in 1: length(DO_stn)) {
        
        new_data <- DO_all[DO_all$Station_ID == DO_stn[j],]
        
          tmp_df <- new_data
          tmp_df$day <- substr(tmp_df$Sampled, 1, 10)
          tmp_df$code <- paste(tmp_df$Station_ID, tmp_df$Analyte, tmp_df$day)
          sub <- with(tmp_df, resolveMRLs(code, Detect, Result))
          tmp_df_MRL <- tmp_df[sub,]
          tmp_df <- remove.dups(tmp_df, min)
          
        #if(!is.na(any(new_data$sdadm))) {
        
        DO_Benuse <- (Ben_use_LU[Ben_use_LU$Station_ID == DO_stn[j], 'DO_use'])
        spwn_time <- as.character(Ben_use_LU[Ben_use_LU$Station_ID == DO_stn[j], 'spwn_time'])
        
        
        DO_evaluate <- EvaluateDOWQS(new_data = tmp_df,
                                     selectUseDO = DO_Benuse,
                                     df.all = df.all, 
                                     selectSpawning = spwn_time,
                                     analyte_column = 'Analyte',
                                     station_id_column = 'Station_ID',
                                     station_desc_column = 'Station_Description',
                                     datetime_column = 'Sampled',
                                     result_column = 'Result',
                                     datetime_format = '%Y-%m-%d %H:%M:%S')
        
        DO_eval <- attr(DO_evaluate, 'ex_df')
        DO_list[[j]] <- DO_evaluate
        DO_exclist[[j]] <- DO_eval
        
      }
    
    
    DO_eval<-rbind.fill(DO_list[])
    exc<-rbind.fill(DO_exclist[])
    
    #exc$Percent_Exceedance <- (exc$Exceedances/exc$Obs) * 100
    
    #results_seaken<-SeaKen %>% filter(analyte == 'Dissolved Oxygen')
    #if(length(DO_stn) > 0) {
      DO_plots<-list()
      
      results_seaken<-SeaKen %>% filter(analyte == 'Dissolved Oxygen')
      
      for (i in 1:length(DO_stn)) {
        
        new_data <- DO_all[DO_all$Station_ID == DO_stn[i],]
        
        trend_logic<-ifelse(grepl("Not Significant", results_seaken[results_seaken$Station_ID == DO_stn[i],'signif']), FALSE,
                            ifelse(grepl("Need at least 8 years", results_seaken[results_seaken$Station_ID == DO_stn[i],'signif']), FALSE, TRUE))
        
        DO_Benuse <- (Ben_use_LU[Ben_use_LU$Station_ID == DO_stn[i], 'DO_use'])
        spwn_time <- as.character(Ben_use_LU[Ben_use_LU$Station_ID == DO_stn[i], 'spwn_time'])
        
        contstns <- c('USGS-14202980', 'USGS-14206694', 'USGS-453004122510301', 'USGS-453030122560101', 'USGS-453040123065201')

       if(DO_stn[i] %in% contstns) {
         trend_logic <- FALSE
       }
        
        b <- plot.DO(new_data = new_data,
                     df.all = df.all,
                     selectUseDO = DO_Benuse[1],
                     sea_ken_table = results_seaken,
                     plot_trend = trend_logic,
                     selectSpawning = spwn_time[1],
                     analyte_column = 'Analyte',
                     station_id_column = 'Station_ID',
                     station_desc_column = 'Station_Description',
                     datetime_column = 'Sampled',
                     result_column = 'Result',
                     datetime_format = '%Y-%m-%d %H:%M:%S',
                     parm = 'Dissolved Oxygen')
        
        DO_plots[[i]]<-b
        
        print(DO_plots[[i]])
        cat(figs(name = paste0('DO_', DO_stn[i]), caption = paste0('Station: ', DO_stn[i], ' _Dissolved Oxygen_ water quality status and trends**')))
      }
    }
    
    DO_table <- as.data.frame(DO_stn_table)
    if(length(DO_stn) > 0){
     # DO_table <- DO_table %>% dplyr::filter(DO_stn %in% DO_stn_table)
      
      DO_table <- DO_table %>% dplyr::filter(!(DO_stn_table %in% DO_stn))
    }
    if (nrow(DO_table) > 0) {
      colnames(DO_table) <- c("Station ID")
      if (!is.null(DO_table)) {
        print("In order to assess against water quality standard, need to add Dissolved Oxygen beneficial uses and spawning time periods to stations.csv for stations:")
        print(DO_table)
      }
    }
    
    colnames(exc) <- c("Station ID", "Station Description", "Obs", "Exceedances", "Meets b/c %Sat", "Min Date", "Max Date")
    if(!is.null(exc)){
      knitr::kable(exc, padding = 2, digits = 1, caption = tbls(name = "doExcTable", caption = "Dissolved Oxygen status and trends**"))
    }
    
  # } else {
  #   print("No monitoring stations fit the criteria to assess Dissolved Oxygen")
  # }
}
DO_exc <- exc

```

# Summary 


```{r Ecoli-summary-map, eval = word_output, fig.cap=figs(name="Ecoli_map", caption="Summary of stations that fit the criteria for status and trend analysis for E coli. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets. Clusters of stations (grey circles located on the western margin of the study area) had insufficient data to determine status and trends for E. coli.**")}

knitr::include_graphics(path = paste0(project_dir,"/Figures/",station_summary_map_ecoli_file))

```

```{r Temp-summary-map, eval = word_output, fig.cap=figs(name="Temperature_map", caption="Summary of stations that fit the criteria for status and trend analysis for temperature. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets.**")}

knitr::include_graphics(path = paste0(project_dir,"/Figures/",station_summary_map_temp_file))

```

```{r ph-summary-map, eval = word_output, fig.cap=figs(name="pH_map", caption="Summary of stations that fit the criteria for status and trend analysis for pH. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets. Clusters of stations (grey circles located on the western margin of the study area) had insufficient data to determine status and trends for pH.**")}

knitr::include_graphics(path = paste0(project_dir,"/Figures/",station_summary_map_pH_file))

```

```{r DO-summary-map, eval = word_output, fig.cap=figs(name="DO_map", caption="Summary of stations that fit the criteria for status and trend analysis for dissolved oxygen. One or more exceedances within the last three years of available data defined whether a station was Meeting or Not Meeting. Trend was determined by significant trends associated with long-term datasets. Clusters of stations (grey circles located on the western margin of the study area) had insufficient data to determine status and trends for dissolved oxygen.**")}

knitr::include_graphics(paste0(project_dir,"/Figures/",station_summary_map_DO_file))

```

Summary of stations that fit the criteria for status and trend analysis. One or more exceedances within the last three years of available data defined whether a station was 'Meeting' or 'Not Meeting'. Trend was determined by significant trends associated with long-term datasets.

```{r parm-summary-table}

stns_param_summary <-  parm_summary(stns = stns[,c(1:4)],
                            ecoli = ecoli,
                            pH = pH,
                            DO_eval = DO_eval,
                            temp = temp,
                            SeaKen = SeaKen,
                            status = status,
                            trend = trend)

# remove duplicate stations w/ same ID but different variation on station name


# create a shapefile
stns_param_summary_shp <- stns_param_summary %>%
                  dplyr::rename(Name=Station_Description, 
                                Latitude=DECIMAL_LAT, 
                                Longitude=DECIMAL_LONG,
                                Ecoli_S=Status_bacteria,
                                Ecoli_T=Trend_bacteria,
                                Temp_S=Status_temp,
                                Temp_T=Trend_temp,
                                pH_S=Status_pH,
                                pH_T=Trend_pH,
                                DO_S=Status_DO,
                                DO_T=Trend_DO)

coordinates(stns_param_summary_shp)=~Longitude+Latitude

# NAD83 : EPSG:4269 <- This is assumed for DATUM
proj4string(stns_param_summary_shp) <- CRS("+init=epsg:4269")

# sort by station ID
stns_param_summary_shp <- stns_param_summary_shp[order(stns_param_summary_shp$Station_ID),]

# write the shapefile
writeOGR(obj=stns_param_summary_shp, dsn=GIS_dir, layer="station_param_summary", driver="ESRI Shapefile", overwrite_layer=TRUE)

colnames(stns_param_summary) <- c("Station ID", "Station Description", 'Latitude', 'Longitude', "Ecoli Status",
                          "Ecoli Trend","Temperature Status", "Temperature Trend", "pH Status", "pH Trend", 
                          "DO Status", "DO Trend")


save(stns_param_summary, file=paste0(Rdata_dir,"/", stns_param_summary_file))

knitr::kable(stns_param_summary, format = "markdown",  padding = 2, digits = 3, 
             caption = tbls(name = "parmSumTable", 
                            caption = "Summary of Monitoring Stations Status and Trend, where 'exceed' represents a single exceedance of the water quality standard within the last two years of available data. Note: DO = dissolved oxygen**"))

```

```{r parm-summary-map-html, results = 'asis', eval = !(word_output)}

agarea_shp <- agwqma_shp[agwqma_shp$PlanName == input$select,]
agarea_shp <-spTransform(agarea_shp, CRS("+proj=longlat +datum=NAD83"))


map2 <- leaflet(agarea_shp) %>%
  addPolygons() %>%
  addTiles() %>%
  addMarkers(lng = stns_param_summary$Longitude,
             lat = stns_param_summary$Latitude,
             popup = paste("<style> div.leaflet-popup-content {width:auto !important;}</style>",
                           lapply(rownames(stns_param_summary), 
                                  function(row) {
                                    htmlTable::htmlTable(stns_param_summary[row,c("Station ID", "Station Description", 
                                                                                  "Ecoli Status", "Ecoli Trend",
                                                                                  "Temperature Status", "Temperature Trend", 
                                                                                  "pH Status", "pH Trend", 
                                                                                  "DO Status", "DO Trend")],
                                                         header = c("Station ID", "Station Description", 
                                                                                  "Ecoli Status", "Ecoli Trend",
                                                                                  "Temperature Status", "Temperature Trend", 
                                                                                  "pH Status", "pH Trend", 
                                                                                  "DO Status", "DO Trend"),
                                                         rnames = FALSE)
                                  })),
             group = 'Station Result Summary') %>%
            addWMSTiles(GetURL("USGSTopo"),
                        attribution = paste0("<a href='https://www.usgs.gov/'>",
                                             "U.S. Geological Survey</a> | ",
                                             "<ahref='https://www.usgs.gov/laws/policies_notices.html'>",
                                             "Policies</a>"),
                         group = "USGS Topo", layers = "0") %>%
             addWMSTiles(GetURL("USGSHydroCached"),
                         group = "Hydrography",
                         options = WMSTileOptions(format = "image/png",
                                                  transparent = TRUE),
                         layers = "0") %>%
            hideGroup("Hydropgraphy")
map2


```

# Conclusions

```{r conclusions-setup}

conclusions.Ecoli <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'Ecoli'), c("conclusion")]
conclusions.Entero <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'Entero'), c("conclusion")]
conclusions.Temp <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'Temp'), c("conclusion")]
conclusions.pH <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'pH'), c("conclusion")]
conclusions.DO <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'DO'), c("conclusion")]
conclusions.TP <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'TP'), c("conclusion")]
conclusions.TSS <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'TSS'), c("conclusion")]
conclusions.add <- Conc_LU[(Conc_LU$AgArea %in% input$select & Conc_LU$topic == 'Add_conc'), c("conclusion")]

```

**What are the overall status or trends?**

* *E. coli*: `r conclusions.Ecoli`
* *Enterococcus*: `r conclusions.Entero`
* *Temperature*: `r conclusions.Temp`
* *pH*: `r conclusions.pH`
* *Dissolved Oxygen*: `r conclusions.DO`
* *Total Phosphorus*: `r conclusions.TP`
* *Total Suspended Solids*: `r conclusions.TSS`


**Additional Conclusions:**

`r paste0("* ",conclusions.add,"\n", collapse="")`


# Appendix

```{r appendix}

org_summary <- summarizeByOrg(df.all)

knitr::kable(org_summary, format = "markdown", padding = 2, digits = 1, caption = tbls(name = "orgSumTable", caption = "Summary table of all unique organizations that were queried; note that organizations included in this table may or may not have had data sufficient for status and/or trends analysis and therefore may not be included in this report**"))

knitr::kable(status, format = "markdown", padding = 2, digits = 1, caption = tbls(name = "statusTable", caption = "Monitoring stations that fit the criteria to assess status; note value represents the number of results for each monitoring station per year**"))

knitr::kable(trend, format = "markdown", padding = 1, digits = 1, caption = tbls(name = "trendTable", caption = "Monitoring stations that fit the criteria to assess trends; note value represents the number of results for each monitoring station per year**"))

knitr::kable(stns_by_year, format = "markdown", padding = 1, digits = 1, caption = tbls(name = "stnByYrTable", caption = "All monitoring stations that were queried and the number of results per year from 2000 to 2017**"))

```

